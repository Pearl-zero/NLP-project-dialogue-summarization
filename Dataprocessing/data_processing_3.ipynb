{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 0. 스페셜 토큰 처리?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분할 x 단어\n",
    "# not_tokenized = ['#Address#', '#CarNumber#', '#CardNumber#', '#DateOfBirth#', '#Email#', \n",
    "#                 '#PassportNumber#', '#Person#', '#Person1#', '#Person2#', '#Person3#', \n",
    "#                 '#Person4#', '#Person5#', '#Person6#', '#Person7#', '#PhoneNumber#', '#SSN#']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. 발화자 / 대화 분리해서 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /data/ephemeral/home/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /data/ephemeral/home/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import random\n",
    "\n",
    "# NLTK 데이터 다운로드 (최초 1회만 필요)\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"단어의 품사를 반환하는 함수\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1]\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag[0], wordnet.NOUN)\n",
    "\n",
    "def synonym_replacement(words, n=1):\n",
    "    \"\"\"동의어로 단어 대체\"\"\"\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    new_words = words.copy()\n",
    "    random_word_list = list(set([word for word in words]))\n",
    "    random.shuffle(random_word_list)\n",
    "    num_replaced = 0\n",
    "    \n",
    "    for random_word in random_word_list:\n",
    "        synonyms = []\n",
    "        try:\n",
    "            for syn in wordnet.synsets(random_word):\n",
    "                for lemma in syn.lemmas():\n",
    "                    # 동의어 추가 (원본 단어와 다른 것만)\n",
    "                    if lemma.name().lower() != random_word.lower():\n",
    "                        synonyms.append(lemma.name())\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        if len(synonyms) >= 1:\n",
    "            synonym = random.choice(list(set(synonyms)))\n",
    "            new_words = [synonym if word == random_word else word for word in new_words]\n",
    "            num_replaced += 1\n",
    "        \n",
    "        if num_replaced >= n:\n",
    "            break\n",
    "    \n",
    "    return new_words\n",
    "\n",
    "def random_insertion(words, n=1):\n",
    "    \"\"\"임의의 동의어 삽입\"\"\"\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    new_words = words.copy()\n",
    "    for _ in range(n):\n",
    "        # 랜덤 단어 선택\n",
    "        if len(new_words) > 0:\n",
    "            random_word = random.choice(new_words)\n",
    "            synonyms = []\n",
    "            try:\n",
    "                for syn in wordnet.synsets(random_word):\n",
    "                    for lemma in syn.lemmas():\n",
    "                        if lemma.name().lower() != random_word.lower():\n",
    "                            synonyms.append(lemma.name())\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            if synonyms:\n",
    "                synonym = random.choice(list(set(synonyms)))\n",
    "                random_index = random.randint(0, len(new_words))\n",
    "                new_words.insert(random_index, synonym)\n",
    "    \n",
    "    return new_words\n",
    "\n",
    "def random_swap(words, n=1):\n",
    "    \"\"\"단어 위치 무작위 교환\"\"\"\n",
    "    new_words = words.copy()\n",
    "    for _ in range(n):\n",
    "        if len(new_words) >= 2:\n",
    "            idx1, idx2 = random.sample(range(len(new_words)), 2)\n",
    "            new_words[idx1], new_words[idx2] = new_words[idx2], new_words[idx1]\n",
    "    return new_words\n",
    "\n",
    "def random_deletion(words, p=0.1):\n",
    "    \"\"\"단어 무작위 삭제\"\"\"\n",
    "    if len(words) == 0:\n",
    "        return words\n",
    "    \n",
    "    new_words = [word for word in words if random.random() > p]\n",
    "    \n",
    "    # 모든 단어가 삭제되는 것을 방지\n",
    "    if len(new_words) == 0:\n",
    "        new_words = [random.choice(words)]\n",
    "    \n",
    "    return new_words\n",
    "\n",
    "def augment_text_data_with_EDA(text, repetition=1):\n",
    "    \"\"\"입력된 문장에 대해 EDA를 통해 데이터 증강\"\"\"\n",
    "    words = text.split()\n",
    "    augmented_texts = []\n",
    "    \n",
    "    for _ in range(repetition):\n",
    "        # 다양한 증강 기법 적용\n",
    "        augmented_list = []\n",
    "        \n",
    "        # 동의어 대체\n",
    "        augmented_list.append(' '.join(synonym_replacement(words)))\n",
    "        \n",
    "        # 랜덤 삽입\n",
    "        augmented_list.append(' '.join(random_insertion(words)))\n",
    "        \n",
    "        # 랜덤 스왑\n",
    "        augmented_list.append(' '.join(random_swap(words)))\n",
    "        \n",
    "        # 랜덤 삭제\n",
    "        augmented_list.append(' '.join(random_deletion(words)))\n",
    "        \n",
    "        augmented_texts.extend(augmented_list)\n",
    "    \n",
    "    return augmented_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 화자와 대화 분리 함수\n",
    "def split_speaker_and_text(dialogue):\n",
    "    \"\"\"대화 내용을 화자 태그와 분리\"\"\"\n",
    "    pattern = r'(#Person\\d+#): (.+)'\n",
    "    lines = dialogue.split('\\n')\n",
    "    return [(match.group(1), match.group(2)) for line in lines if (match := re.match(pattern, line))]\n",
    "\n",
    "# 화자와 대화 결합 함수\n",
    "def join_speaker_and_text(speaker_text_pairs):\n",
    "    \"\"\"화자 태그와 대화 내용을 결합\"\"\"\n",
    "    return '\\n'.join([f'{speaker}: {text}' for speaker, text in speaker_text_pairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1 rows out of 12457\n",
      "Processed 101 rows out of 12457\n",
      "Processed 201 rows out of 12457\n",
      "Processed 301 rows out of 12457\n",
      "Processed 401 rows out of 12457\n",
      "Processed 501 rows out of 12457\n",
      "Processed 601 rows out of 12457\n",
      "Processed 701 rows out of 12457\n",
      "Processed 801 rows out of 12457\n",
      "Processed 901 rows out of 12457\n",
      "Processed 1001 rows out of 12457\n",
      "Processed 1101 rows out of 12457\n",
      "Processed 1201 rows out of 12457\n",
      "Processed 1301 rows out of 12457\n",
      "Processed 1401 rows out of 12457\n",
      "Processed 1501 rows out of 12457\n",
      "Processed 1601 rows out of 12457\n",
      "Processed 1701 rows out of 12457\n",
      "Processed 1801 rows out of 12457\n",
      "Processed 1901 rows out of 12457\n",
      "Processed 2001 rows out of 12457\n",
      "Processed 2101 rows out of 12457\n",
      "Processed 2201 rows out of 12457\n",
      "Processed 2301 rows out of 12457\n",
      "Processed 2401 rows out of 12457\n",
      "Processed 2501 rows out of 12457\n",
      "Processed 2601 rows out of 12457\n",
      "Processed 2701 rows out of 12457\n",
      "Processed 2801 rows out of 12457\n",
      "Processed 2901 rows out of 12457\n",
      "Processed 3001 rows out of 12457\n",
      "Processed 3101 rows out of 12457\n",
      "Processed 3201 rows out of 12457\n",
      "Processed 3301 rows out of 12457\n",
      "Processed 3401 rows out of 12457\n",
      "Processed 3501 rows out of 12457\n",
      "Processed 3601 rows out of 12457\n",
      "Processed 3701 rows out of 12457\n",
      "Processed 3801 rows out of 12457\n",
      "Processed 3901 rows out of 12457\n",
      "Processed 4001 rows out of 12457\n",
      "Processed 4101 rows out of 12457\n",
      "Processed 4201 rows out of 12457\n",
      "Processed 4301 rows out of 12457\n",
      "Processed 4401 rows out of 12457\n",
      "Processed 4501 rows out of 12457\n",
      "Processed 4601 rows out of 12457\n",
      "Processed 4701 rows out of 12457\n",
      "Processed 4801 rows out of 12457\n",
      "Processed 4901 rows out of 12457\n",
      "Processed 5001 rows out of 12457\n",
      "Processed 5101 rows out of 12457\n",
      "Processed 5201 rows out of 12457\n",
      "Processed 5301 rows out of 12457\n",
      "Processed 5401 rows out of 12457\n",
      "Processed 5501 rows out of 12457\n",
      "Processed 5601 rows out of 12457\n",
      "Processed 5701 rows out of 12457\n",
      "Processed 5801 rows out of 12457\n",
      "Processed 5901 rows out of 12457\n",
      "Processed 6001 rows out of 12457\n",
      "Processed 6101 rows out of 12457\n",
      "Processed 6201 rows out of 12457\n",
      "Processed 6301 rows out of 12457\n",
      "Processed 6401 rows out of 12457\n",
      "Processed 6501 rows out of 12457\n",
      "Processed 6601 rows out of 12457\n",
      "Processed 6701 rows out of 12457\n",
      "Processed 6801 rows out of 12457\n",
      "Processed 6901 rows out of 12457\n",
      "Processed 7001 rows out of 12457\n",
      "Processed 7101 rows out of 12457\n",
      "Processed 7201 rows out of 12457\n",
      "Processed 7301 rows out of 12457\n",
      "Processed 7401 rows out of 12457\n",
      "Processed 7501 rows out of 12457\n",
      "Processed 7601 rows out of 12457\n",
      "Processed 7701 rows out of 12457\n",
      "Processed 7801 rows out of 12457\n",
      "Processed 7901 rows out of 12457\n",
      "Processed 8001 rows out of 12457\n",
      "Processed 8101 rows out of 12457\n",
      "Processed 8201 rows out of 12457\n",
      "Processed 8301 rows out of 12457\n",
      "Processed 8401 rows out of 12457\n",
      "Processed 8501 rows out of 12457\n",
      "Processed 8601 rows out of 12457\n",
      "Processed 8701 rows out of 12457\n",
      "Processed 8801 rows out of 12457\n",
      "Processed 8901 rows out of 12457\n",
      "Processed 9001 rows out of 12457\n",
      "Processed 9101 rows out of 12457\n",
      "Processed 9201 rows out of 12457\n",
      "Processed 9301 rows out of 12457\n",
      "Processed 9401 rows out of 12457\n",
      "Processed 9501 rows out of 12457\n",
      "Processed 9601 rows out of 12457\n",
      "Processed 9701 rows out of 12457\n",
      "Processed 9801 rows out of 12457\n",
      "Processed 9901 rows out of 12457\n",
      "Processed 10001 rows out of 12457\n",
      "Processed 10101 rows out of 12457\n",
      "Processed 10201 rows out of 12457\n",
      "Processed 10301 rows out of 12457\n",
      "Processed 10401 rows out of 12457\n",
      "Processed 10501 rows out of 12457\n",
      "Processed 10601 rows out of 12457\n",
      "Processed 10701 rows out of 12457\n",
      "Processed 10801 rows out of 12457\n",
      "Processed 10901 rows out of 12457\n",
      "Processed 11001 rows out of 12457\n",
      "Processed 11101 rows out of 12457\n",
      "Processed 11201 rows out of 12457\n",
      "Processed 11301 rows out of 12457\n",
      "Processed 11401 rows out of 12457\n",
      "Processed 11501 rows out of 12457\n",
      "Processed 11601 rows out of 12457\n",
      "Processed 11701 rows out of 12457\n",
      "Processed 11801 rows out of 12457\n",
      "Processed 11901 rows out of 12457\n",
      "Processed 12001 rows out of 12457\n",
      "Processed 12101 rows out of 12457\n",
      "Processed 12201 rows out of 12457\n",
      "Processed 12301 rows out of 12457\n",
      "Processed 12401 rows out of 12457\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "df = pd.read_csv('/root/NLP/data/train.csv')\n",
    "df_filtered = df[['fname', 'dialogue', 'summary', 'topic']]\n",
    "\n",
    "# 증강 데이터를 저장할 리스트\n",
    "augmented_rows = []\n",
    "\n",
    "# EDA 적용 및 데이터 증강\n",
    "for index, row in df_filtered.iterrows():\n",
    "    original_text = row['dialogue']\n",
    "\n",
    "    # 화자 태그와 대화 내용 분리\n",
    "    speaker_text_pairs = split_speaker_and_text(original_text)\n",
    "\n",
    "    # 대화 내용에 EDA 적용\n",
    "    augmented_text_lists = [\n",
    "        augment_text_data_with_EDA(text, repetition=3) for _, text in speaker_text_pairs\n",
    "    ]\n",
    "\n",
    "    # EDA 결과와 화자 태그 결합\n",
    "    for augmented_texts in zip(*augmented_text_lists):\n",
    "        new_speaker_text_pairs = [\n",
    "            (speaker_text_pairs[i][0], augmented_text) \n",
    "            for i, augmented_text in enumerate(augmented_texts)\n",
    "        ]\n",
    "        augmented_dialogue = join_speaker_and_text(new_speaker_text_pairs)\n",
    "\n",
    "        # 증강 데이터를 새로운 행으로 추가\n",
    "        augmented_rows.append({\n",
    "            'fname': row['fname'],\n",
    "            'dialogue': augmented_dialogue,\n",
    "            'summary': row['summary'],\n",
    "            'topic': row['topic']\n",
    "        })\n",
    "\n",
    "    # 진행 상황 출력\n",
    "    if index % 100 == 0:\n",
    "        print(f\"Processed {index + 1} rows out of {len(df_filtered)}\")\n",
    "\n",
    "# 증강 데이터를 DataFrame으로 변환\n",
    "augmented_data = pd.DataFrame(augmented_rows)\n",
    "\n",
    "# 결과 저장\n",
    "augmented_data.to_csv('/root/NLP/data/aug_nltk_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>#Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나...</td>\n",
       "      <td>스미스씨가 건강검진을 받고 있고, 호킨스 의사는 매년 건강검진을 받는 것을 권장합니...</td>\n",
       "      <td>건강검진 받기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_0</td>\n",
       "      <td>#Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나...</td>\n",
       "      <td>스미스씨가 건강검진을 받고 있고, 호킨스 의사는 매년 건강검진을 받는 것을 권장합니...</td>\n",
       "      <td>건강검진 받기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_0</td>\n",
       "      <td>#Person1#: 안녕하세요, 스미스씨. 저는 의사입니다. 호킨스 오늘 왜 오셨나...</td>\n",
       "      <td>스미스씨가 건강검진을 받고 있고, 호킨스 의사는 매년 건강검진을 받는 것을 권장합니...</td>\n",
       "      <td>건강검진 받기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_0</td>\n",
       "      <td>#Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나...</td>\n",
       "      <td>스미스씨가 건강검진을 받고 있고, 호킨스 의사는 매년 건강검진을 받는 것을 권장합니...</td>\n",
       "      <td>건강검진 받기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_0</td>\n",
       "      <td>#Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나...</td>\n",
       "      <td>스미스씨가 건강검진을 받고 있고, 호킨스 의사는 매년 건강검진을 받는 것을 권장합니...</td>\n",
       "      <td>건강검진 받기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149479</th>\n",
       "      <td>train_12459</td>\n",
       "      <td>#Person1#: 엄마, 다음 토요일에 이 삼촌네 가족을 방문하기 위해 비행기를 ...</td>\n",
       "      <td>#Person1#은 다음 토요일에 이 삼촌네를 방문할 때 가방을 어떻게 싸야 할지 ...</td>\n",
       "      <td>짐 싸기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149480</th>\n",
       "      <td>train_12459</td>\n",
       "      <td>#Person1#: 엄마, 다음 토요일에 이 삼촌네 가족을 방문하기 위해 비행기를 ...</td>\n",
       "      <td>#Person1#은 다음 토요일에 이 삼촌네를 방문할 때 가방을 어떻게 싸야 할지 ...</td>\n",
       "      <td>짐 싸기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149481</th>\n",
       "      <td>train_12459</td>\n",
       "      <td>#Person1#: 엄마, 다음 토요일에 이 삼촌네 가족을 방문하기 위해 비행기를 ...</td>\n",
       "      <td>#Person1#은 다음 토요일에 이 삼촌네를 방문할 때 가방을 어떻게 싸야 할지 ...</td>\n",
       "      <td>짐 싸기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149482</th>\n",
       "      <td>train_12459</td>\n",
       "      <td>#Person1#: 엄마, 다음 가족을 이 삼촌네 토요일에 방문하기 위해 비행기를 ...</td>\n",
       "      <td>#Person1#은 다음 토요일에 이 삼촌네를 방문할 때 가방을 어떻게 싸야 할지 ...</td>\n",
       "      <td>짐 싸기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149483</th>\n",
       "      <td>train_12459</td>\n",
       "      <td>#Person1#: 엄마, 다음 토요일에 이 삼촌네 가족을 방문하기 위해 비행기를 ...</td>\n",
       "      <td>#Person1#은 다음 토요일에 이 삼촌네를 방문할 때 가방을 어떻게 싸야 할지 ...</td>\n",
       "      <td>짐 싸기</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149484 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              fname                                           dialogue  \\\n",
       "0           train_0  #Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나...   \n",
       "1           train_0  #Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나...   \n",
       "2           train_0  #Person1#: 안녕하세요, 스미스씨. 저는 의사입니다. 호킨스 오늘 왜 오셨나...   \n",
       "3           train_0  #Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나...   \n",
       "4           train_0  #Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나...   \n",
       "...             ...                                                ...   \n",
       "149479  train_12459  #Person1#: 엄마, 다음 토요일에 이 삼촌네 가족을 방문하기 위해 비행기를 ...   \n",
       "149480  train_12459  #Person1#: 엄마, 다음 토요일에 이 삼촌네 가족을 방문하기 위해 비행기를 ...   \n",
       "149481  train_12459  #Person1#: 엄마, 다음 토요일에 이 삼촌네 가족을 방문하기 위해 비행기를 ...   \n",
       "149482  train_12459  #Person1#: 엄마, 다음 가족을 이 삼촌네 토요일에 방문하기 위해 비행기를 ...   \n",
       "149483  train_12459  #Person1#: 엄마, 다음 토요일에 이 삼촌네 가족을 방문하기 위해 비행기를 ...   \n",
       "\n",
       "                                                  summary    topic  \n",
       "0       스미스씨가 건강검진을 받고 있고, 호킨스 의사는 매년 건강검진을 받는 것을 권장합니...  건강검진 받기  \n",
       "1       스미스씨가 건강검진을 받고 있고, 호킨스 의사는 매년 건강검진을 받는 것을 권장합니...  건강검진 받기  \n",
       "2       스미스씨가 건강검진을 받고 있고, 호킨스 의사는 매년 건강검진을 받는 것을 권장합니...  건강검진 받기  \n",
       "3       스미스씨가 건강검진을 받고 있고, 호킨스 의사는 매년 건강검진을 받는 것을 권장합니...  건강검진 받기  \n",
       "4       스미스씨가 건강검진을 받고 있고, 호킨스 의사는 매년 건강검진을 받는 것을 권장합니...  건강검진 받기  \n",
       "...                                                   ...      ...  \n",
       "149479  #Person1#은 다음 토요일에 이 삼촌네를 방문할 때 가방을 어떻게 싸야 할지 ...     짐 싸기  \n",
       "149480  #Person1#은 다음 토요일에 이 삼촌네를 방문할 때 가방을 어떻게 싸야 할지 ...     짐 싸기  \n",
       "149481  #Person1#은 다음 토요일에 이 삼촌네를 방문할 때 가방을 어떻게 싸야 할지 ...     짐 싸기  \n",
       "149482  #Person1#은 다음 토요일에 이 삼촌네를 방문할 때 가방을 어떻게 싸야 할지 ...     짐 싸기  \n",
       "149483  #Person1#은 다음 토요일에 이 삼촌네를 방문할 때 가방을 어떻게 싸야 할지 ...     짐 싸기  \n",
       "\n",
       "[149484 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. df + augmented_data concat하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. 인덱스 reset / fname 열 바꾸기(train_0 ~ train?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
