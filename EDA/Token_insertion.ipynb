{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dialogue_lengths(df):\n",
    "    \"\"\"대화 길이 분포 분석\"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"digit82/kobart-summarization\")\n",
    "    \n",
    "    # 토큰 길이 계산\n",
    "    token_lengths = []\n",
    "    for text in df['dialogue']:\n",
    "        tokens = tokenizer.encode(text)\n",
    "        token_lengths.append(len(tokens))\n",
    "    \n",
    "    # 길이 통계\n",
    "    length_stats = {\n",
    "        'mean': np.mean(token_lengths),\n",
    "        'median': np.median(token_lengths),\n",
    "        'p95': np.percentile(token_lengths, 95),\n",
    "        'max': np.max(token_lengths),\n",
    "        'min': np.min(token_lengths)\n",
    "    }\n",
    "    \n",
    "    return length_stats, token_lengths\n",
    "\n",
    "def analyze_dialogue_patterns(df):\n",
    "    \"\"\"대화 패턴 분석\"\"\"\n",
    "    # 감정 표현 패턴\n",
    "    emotion_patterns = {\n",
    "        'happy': r'(좋아|기쁘|행복|즐거|웃)',\n",
    "        'sad': r'(슬프|우울|안타깝|힘들)',\n",
    "        'angry': r'(화나|짜증|싫|못마땅|불편)',\n",
    "        'neutral': r'(그렇군요|알겠습니다|네)'\n",
    "    }\n",
    "    \n",
    "    # 대화 의도 패턴\n",
    "    intent_patterns = {\n",
    "        'question': r'(\\?|궁금|어떻|무엇|언제|어디|누구)',\n",
    "        'suggestion': r'(제안|추천|하는 게 어떨까|면 좋겠|면 어떨까)',\n",
    "        'opinion': r'(생각|의견|보면|같아)'\n",
    "    }\n",
    "    \n",
    "    # 패턴 빈도수 계산\n",
    "    pattern_counts = {\n",
    "        'emotions': defaultdict(int),\n",
    "        'intents': defaultdict(int)\n",
    "    }\n",
    "    \n",
    "    for text in df['dialogue']:\n",
    "        # 감정 패턴 확인\n",
    "        for emotion, pattern in emotion_patterns.items():\n",
    "            if re.search(pattern, text):\n",
    "                pattern_counts['emotions'][emotion] += 1\n",
    "        \n",
    "        # 의도 패턴 확인\n",
    "        for intent, pattern in intent_patterns.items():\n",
    "            if re.search(pattern, text):\n",
    "                pattern_counts['intents'][intent] += 1\n",
    "    \n",
    "    return pattern_counts, emotion_patterns, intent_patterns\n",
    "\n",
    "def insert_special_tokens(text, emotion_patterns, intent_patterns):\n",
    "    \"\"\"패턴 분석 결과를 바탕으로 special tokens 삽입\"\"\"\n",
    "    modified_text = text\n",
    "    \n",
    "    # 감정 패턴에 따른 토큰 삽입\n",
    "    for emotion, pattern in emotion_patterns.items():\n",
    "        if re.search(pattern, text):\n",
    "            modified_text = f\"#{emotion.capitalize()}# \" + modified_text\n",
    "    \n",
    "    # 의도 패턴에 따른 토큰 삽입\n",
    "    for intent, pattern in intent_patterns.items():\n",
    "        if re.search(pattern, text):\n",
    "            modified_text = f\"#{intent.capitalize()}# \" + modified_text\n",
    "    \n",
    "    # 화자 전환 표시\n",
    "    turns = modified_text.split('\\n')\n",
    "    processed_turns = []\n",
    "    for turn in turns:\n",
    "        if turn.strip():\n",
    "            processed_turns.append(f\"#Turn# {turn}\")\n",
    "    \n",
    "    return '\\n'.join(processed_turns)\n",
    "\n",
    "def process_dataset(df):\n",
    "    \"\"\"전체 데이터셋 처리\"\"\"\n",
    "    # 길이 분석\n",
    "    length_stats, token_lengths = analyze_dialogue_lengths(df)\n",
    "    print(\"Dialogue Length Statistics:\")\n",
    "    print(length_stats)\n",
    "    \n",
    "    # 패턴 분석\n",
    "    pattern_counts, emotion_patterns, intent_patterns = analyze_dialogue_patterns(df)\n",
    "    print(\"\\nPattern Frequencies:\")\n",
    "    print(pattern_counts)\n",
    "    \n",
    "    # 가장 빈번한 패턴들을 기반으로 special tokens 결정\n",
    "    recommended_tokens = []\n",
    "    for category, counts in pattern_counts.items():\n",
    "        # 일정 빈도 이상 나타나는 패턴만 선택\n",
    "        threshold = len(df) * 0.05  # 5% 이상 출현하는 패턴만 선택\n",
    "        frequent_patterns = [k for k, v in counts.items() if v > threshold]\n",
    "        recommended_tokens.extend([f\"#{p.capitalize()}#\" for p in frequent_patterns])\n",
    "    \n",
    "    print(\"\\nRecommended Special Tokens:\")\n",
    "    print(recommended_tokens)\n",
    "    \n",
    "    # optimal encoder_max_len 추천\n",
    "    recommended_max_len = int(np.percentile(token_lengths, 95))  # 95퍼센타일 값 사용\n",
    "    print(f\"\\nRecommended encoder_max_len: {recommended_max_len}\")\n",
    "    \n",
    "    # 토큰 삽입 예시\n",
    "    sample_processed = insert_special_tokens(df['dialogue'].iloc[0], emotion_patterns, intent_patterns)\n",
    "    print(\"\\nProcessed Text Example:\")\n",
    "    print(sample_processed)\n",
    "    \n",
    "    return recommended_tokens, recommended_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue Length Statistics:\n",
      "{'mean': 206.41262069903442, 'median': 188.0, 'p95': 378.0, 'max': 1324, 'min': 29}\n",
      "\n",
      "Pattern Frequencies:\n",
      "{'emotions': defaultdict(<class 'int'>, {'neutral': 20476, 'sad': 1321, 'happy': 10534, 'angry': 1325}), 'intents': defaultdict(<class 'int'>, {'question': 28338, 'opinion': 13160, 'suggestion': 2811})}\n",
      "\n",
      "Recommended Special Tokens:\n",
      "['#Neutral#', '#Happy#', '#Question#', '#Opinion#', '#Suggestion#']\n",
      "\n",
      "Recommended encoder_max_len: 378\n",
      "\n",
      "Processed Text Example:\n",
      "#Turn# #Opinion# #Question# #Neutral# #Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나요?\n",
      "#Turn# #Person2#: 건강검진을 받는 것이 좋을 것 같아서요.\n",
      "#Turn# #Person1#: 그렇군요, 당신은 5년 동안 건강검진을 받지 않았습니다. 매년 받아야 합니다.\n",
      "#Turn# #Person2#: 알고 있습니다. 하지만 아무 문제가 없다면 왜 의사를 만나러 가야 하나요?\n",
      "#Turn# #Person1#: 심각한 질병을 피하는 가장 좋은 방법은 이를 조기에 발견하는 것입니다. 그러니 당신의 건강을 위해 최소한 매년 한 번은 오세요.\n",
      "#Turn# #Person2#: 알겠습니다.\n",
      "#Turn# #Person1#: 여기 보세요. 당신의 눈과 귀는 괜찮아 보입니다. 깊게 숨을 들이쉬세요. 스미스씨, 담배 피우시나요?\n",
      "#Turn# #Person2#: 네.\n",
      "#Turn# #Person1#: 당신도 알다시피, 담배는 폐암과 심장병의 주요 원인입니다. 정말로 끊으셔야 합니다. \n",
      "#Turn# #Person2#: 수백 번 시도했지만, 습관을 버리는 것이 어렵습니다.\n",
      "#Turn# #Person1#: 우리는 도움이 될 수 있는 수업과 약물들을 제공하고 있습니다. 나가기 전에 더 많은 정보를 드리겠습니다.\n",
      "#Turn# #Person2#: 알겠습니다, 감사합니다, 의사선생님.\n"
     ]
    }
   ],
   "source": [
    "# 사용 예시:\n",
    "df = pd.read_csv('/root/NLP/data/sum_aug_bt.csv')\n",
    "recommended_tokens, recommended_max_len = process_dataset(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
