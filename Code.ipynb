{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6n-Ps2nkVsBb"
   },
   "source": [
    "# **ğŸ’ğŸ»ğŸ—¨ï¸ğŸ’ğŸ»â€â™‚ï¸ëŒ€í™” ìš”ì•½ Baseline code**\n",
    "> **Dialogue Summarization** ê²½ì§„ëŒ€íšŒì— ì˜¤ì‹  ì—¬ëŸ¬ë¶„ í™˜ì˜í•©ë‹ˆë‹¤! ğŸ‰    \n",
    "> ë³¸ ëŒ€íšŒì—ì„œëŠ” ìµœì†Œ 2ëª…ì—ì„œ ìµœëŒ€ 7ëª…ì´ ë“±ì¥í•˜ì—¬ ë‚˜ëˆ„ëŠ” ëŒ€í™”ë¥¼ ìš”ì•½í•˜ëŠ” BART ê¸°ë°˜ ëª¨ë¸ì˜ baseline codeë¥¼ ì œê³µí•©ë‹ˆë‹¤.     \n",
    "> ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ì¼ìƒ ëŒ€í™”ì— ëŒ€í•œ ìš”ì•½ì„ íš¨ê³¼ì ìœ¼ë¡œ ìƒì„±í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“¤ì–´ë´…ì‹œë‹¤!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNq_LylZa1ug"
   },
   "source": [
    "## âš™ï¸ ë°ì´í„° ë° í™˜ê²½ì„¤ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjCiuI_V4glr"
   },
   "source": [
    "### 1) í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYqDF_-r2ToB"
   },
   "source": [
    "- í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•œ í›„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "id": "zbZ7SU9P2TYN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import yaml\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from rouge import Rouge # ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.\n",
    "\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration, BartConfig\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "# import wandb # ëª¨ë¸ í•™ìŠµ ê³¼ì •ì„ ì†ì‰½ê²Œ Trackingí•˜ê³ , ì‹œê°í™”í•  ìˆ˜ ìˆëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Qq46k6_CNQn"
   },
   "source": [
    "### 2) Config file ë§Œë“¤ê¸° (ì„ íƒ)\n",
    "- ëª¨ë¸ ìƒì„±ì— í•„ìš”í•œ ë‹¤ì–‘í•œ ë§¤ê°œë³€ìˆ˜ ì •ë³´ë¥¼ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
    "  ë”°ë¼ì„œ, ì½”ë“œ ìƒì—ì„œ ëª¨ë¸ì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ì„¤ì •í•  ìˆ˜ë„ ìˆì§€ë§Œ ë…ë¦½ì ì¸ ë§¤ê°œë³€ìˆ˜ ì •ë³´ íŒŒì¼ì„ ìƒì„±í•˜ì—¬ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  16640 KiB |  16640 KiB |   1503 TiB |   1503 TiB |\n",
      "|       from large pool |  16640 KiB |  16640 KiB |   1493 TiB |   1493 TiB |\n",
      "|       from small pool |      0 KiB |      0 KiB |      9 TiB |      9 TiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  16640 KiB |  16640 KiB |   1503 TiB |   1503 TiB |\n",
      "|       from large pool |  16640 KiB |  16640 KiB |   1493 TiB |   1493 TiB |\n",
      "|       from small pool |      0 KiB |      0 KiB |      9 TiB |      9 TiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |  16640 KiB |  16640 KiB |   1498 TiB |   1498 TiB |\n",
      "|       from large pool |  16640 KiB |  16640 KiB |   1488 TiB |   1488 TiB |\n",
      "|       from small pool |      0 KiB |      0 KiB |      9 TiB |      9 TiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |    820 MiB |    820 MiB | 161420 MiB | 160600 MiB |\n",
      "|       from large pool |    820 MiB |    820 MiB | 161158 MiB | 160338 MiB |\n",
      "|       from small pool |      0 MiB |      0 MiB |    262 MiB |    262 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |    803 MiB |    803 MiB |    930 TiB |    930 TiB |\n",
      "|       from large pool |    803 MiB |    803 MiB |    920 TiB |    920 TiB |\n",
      "|       from small pool |      0 MiB |      0 MiB |     10 TiB |     10 TiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       2    |       2    |   91224 K  |   91224 K  |\n",
      "|       from large pool |       2    |       2    |   38076 K  |   38076 K  |\n",
      "|       from small pool |       0    |       0    |   53147 K  |   53147 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       2    |       2    |   91224 K  |   91224 K  |\n",
      "|       from large pool |       2    |       2    |   38076 K  |   38076 K  |\n",
      "|       from small pool |       0    |       0    |   53147 K  |   53147 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       2    |       2    |     822    |     820    |\n",
      "|       from large pool |       2    |       2    |     691    |     689    |\n",
      "|       from small pool |       0    |       0    |     131    |     131    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       4    |       4    |   43690 K  |   43690 K  |\n",
      "|       from large pool |       4    |       4    |   19529 K  |   19529 K  |\n",
      "|       from small pool |       0    |       0    |   24161 K  |   24161 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digit82/kobart-summarization\n",
    "# gogamza/kobart-summarization\n",
    "# EbanLee/kobart-summary-v3\n",
    "# gogamza/kobart-base-v2\n",
    "set_model_name = 'digit82/kobart-summarization'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625eec74db344f7fa0dfaca37dc1a4ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.177 MB uploaded\\r'), FloatProgress(value=0.032288524731693365, max=1â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–ˆâ–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–</td></tr><tr><td>eval/rouge-1</td><td>â–ƒâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ƒâ–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‚â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>eval/rouge-2</td><td>â–ƒâ–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ƒâ–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>eval/rouge-l</td><td>â–‚â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ƒâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‚â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>eval/runtime</td><td>â–ˆâ–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ˆâ–‚â–ƒâ–ƒâ–„â–‚â–‚â–ƒâ–ˆâ–ƒâ–ƒâ–„â–‚â–‚â–â–ƒâ–‡â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ˆâ–â–„â–‚â–ƒâ–â–‚â–‚</td></tr><tr><td>eval/samples_per_second</td><td>â–â–„â–†â–…â–‡â–†â–‡â–†â–â–‡â–…â–…â–…â–†â–‡â–†â–â–†â–…â–…â–†â–†â–ˆâ–†â–â–†â–†â–‡â–†â–‡â–‡â–†â–â–ˆâ–…â–‡â–…â–‡â–‡â–‡</td></tr><tr><td>eval/steps_per_second</td><td>â–â–„â–†â–…â–‡â–†â–‡â–†â–â–‡â–…â–…â–…â–†â–‡â–†â–â–†â–…â–…â–†â–†â–ˆâ–†â–â–†â–†â–‡â–†â–‡â–‡â–†â–â–ˆâ–…â–‡â–…â–‡â–‡â–‡</td></tr><tr><td>train/epoch</td><td>â–â–‚â–‚â–„â–…â–†â–‡â–ˆâ–â–‚â–ƒâ–„â–…â–†â–‡â–ˆâ–â–‚â–ƒâ–…â–…â–†â–‡â–ˆâ–â–‚â–ƒâ–„â–…â–†â–‡â–ˆâ–â–‚â–ƒâ–…â–…â–‡â–‡â–ˆ</td></tr><tr><td>train/global_step</td><td>â–â–‚â–‚â–„â–…â–†â–‡â–ˆâ–â–‚â–ƒâ–„â–…â–†â–‡â–ˆâ–â–‚â–ƒâ–…â–…â–†â–‡â–ˆâ–â–‚â–ƒâ–„â–…â–†â–‡â–ˆâ–â–‚â–ƒâ–…â–…â–‡â–‡â–ˆ</td></tr><tr><td>train/learning_rate</td><td>â–â–ˆâ–ˆâ–‡â–†â–…â–„â–‚â–â–ˆâ–ˆâ–‡â–†â–…â–„â–â–â–ˆâ–ˆâ–‡â–†â–…â–‚â–â–â–ˆâ–ˆâ–‡â–†â–†â–„â–‚â–â–ˆâ–ˆâ–‡â–†â–…â–„â–</td></tr><tr><td>train/loss</td><td>â–ˆâ–‚â–â–â–â–â–â–â–ˆâ–‚â–â–â–â–â–â–â–ˆâ–‚â–â–â–â–â–â–â–†â–‚â–â–â–â–â–â–â–†â–‚â–â–â–â–â–â–</td></tr><tr><td>train/total_flos</td><td>â–â–â–â–â–</td></tr><tr><td>train/train_loss</td><td>â–ˆâ–ˆâ–ˆâ–â–</td></tr><tr><td>train/train_runtime</td><td>â–ˆâ–†â–†â–â–„</td></tr><tr><td>train/train_samples_per_second</td><td>â–â–ƒâ–ƒâ–ˆâ–…</td></tr><tr><td>train/train_steps_per_second</td><td>â–â–ƒâ–ƒâ–ˆâ–…</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.56433</td></tr><tr><td>eval/rouge-1</td><td>0.37989</td></tr><tr><td>eval/rouge-2</td><td>0.14164</td></tr><tr><td>eval/rouge-l</td><td>0.36588</td></tr><tr><td>eval/runtime</td><td>9.7038</td></tr><tr><td>eval/samples_per_second</td><td>51.423</td></tr><tr><td>eval/steps_per_second</td><td>1.649</td></tr><tr><td>train/epoch</td><td>11.0</td></tr><tr><td>train/global_step</td><td>2750</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.3998</td></tr><tr><td>train/total_flos</td><td>4.177517883162624e+16</td></tr><tr><td>train/train_loss</td><td>1.0075</td></tr><tr><td>train/train_runtime</td><td>1214.2508</td></tr><tr><td>train/train_samples_per_second</td><td>205.18</td></tr><tr><td>train/train_steps_per_second</td><td>4.118</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">flowing-energy-7</strong> at: <a href='https://wandb.ai/pearlzero21-sk-telecom/huggingface/runs/ymdwrz7j' target=\"_blank\">https://wandb.ai/pearlzero21-sk-telecom/huggingface/runs/ymdwrz7j</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241127_111218-ymdwrz7j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# print(wandb.run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"baseline_333.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197,
     "referenced_widgets": [
      "e920dbc173c045d1a32143349f1dff8e",
      "58c794fb7ce543a39fdf66d757f6eeab",
      "8a6464a355f7464c989033965d418a8a",
      "3645438ace1f4596a8dbc157b48c1521",
      "58001a60eacc44d5b38a68648adccde4",
      "6f5fde5b0ac840a18bd5cc380e564ff6",
      "45187decb58b4ad39ad532259c6277e5",
      "2307c6dcbe0141acb5e61baae19cade7",
      "4747b668e2fa4ab58a449446f80030f5",
      "14f6c91d6c634379b498586c51e606e0",
      "08d05bc20a96432badd459e1ffaf868e",
      "5dfcf310ca9e4e2794076098a5d69cea",
      "3c284a826f6843f6aa47eacad478ac30",
      "6caedd60c6b747469c82930be1f95d6d",
      "64f2218f899d446393cfea44f206f0a6",
      "d068f541df3f438dbd5138863e64b2f2",
      "affff1d8a89e4c14955d1b2aa39ff1ab",
      "13651c09564a4337b8274c1cb436faa5",
      "3bcd6b6b956347b29e1efa20a1d00542",
      "2fd3d7bbcd6948d8904d33001f95ea03",
      "d22fbc2c5dbf422399e496c9b500025a",
      "775d8bbeceac4e2da4f21ab6235c89ed",
      "de1a3f7701c243839fe03b930a9b9e30",
      "ebc22683058a4f229c5588e52fc93536",
      "52095cc7087243ac916055e569fd22f3",
      "a15af9e8158f4903b9189f3d322a5ef3",
      "21d2e54b5a0a4f79973a512105da43eb",
      "083ea69907bb48d4a8fff919bac51aad",
      "2a190bda0b72407e9a953cd2104dd3b2",
      "c18f0e3bc35e44d9915c3f84cd282a26",
      "3a04e871b74b45d7bf02fd33bb103577",
      "ac00d6c2cf974b33a628acb3f1471316",
      "285007b45236478ca147c6df752c8da4"
     ]
    },
    "id": "gZOE9TInCQHJ",
    "outputId": "8ce58487-6199-408c-cb37-49af1e218bc2"
   },
   "outputs": [],
   "source": [
    "# config ì„¤ì •ì— tokenizer ëª¨ë“ˆì´ ì‚¬ìš©ë˜ë¯€ë¡œ ë¯¸ë¦¬ tokenizerë¥¼ ì •ì˜í•´ì¤ë‹ˆë‹¤.\n",
    "tokenizer = AutoTokenizer.from_pretrained(set_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "id": "5vsACJI7CVb8"
   },
   "outputs": [],
   "source": [
    "config_data = {\n",
    "    \"general\": {\n",
    "        \"data_path\": \"/root/NLP/data/\", # ëª¨ë¸ ìƒì„±ì— í•„ìš”í•œ ë°ì´í„° ê²½ë¡œë¥¼ ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "        \"model_name\": f\"{set_model_name}\", # ë¶ˆëŸ¬ì˜¬ ëª¨ë¸ì˜ ì´ë¦„ì„ ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "        \"output_dir\": f\"./ckp/{set_model_name}/\" # ëª¨ë¸ì˜ ìµœì¢… ì¶œë ¥ ê°’ì„ ì €ì¥í•  ê²½ë¡œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    },\n",
    "    \"tokenizer\": {\n",
    "        \"encoder_max_len\": 512,\n",
    "        \"decoder_max_len\": 100,\n",
    "        \"bos_token\": f\"{tokenizer.bos_token}\",\n",
    "        \"eos_token\": f\"{tokenizer.eos_token}\",\n",
    "        # íŠ¹ì • ë‹¨ì–´ë“¤ì´ ë¶„í•´ë˜ì–´ tokenizationì´ ìˆ˜í–‰ë˜ì§€ ì•Šë„ë¡ special_tokensì„ ì§€ì •í•´ì¤ë‹ˆë‹¤.\n",
    "        \"special_tokens\": ['#Person1#', '#Person2#', '#Person3#', '#PhoneNumber#', '#Address#', '#PassportNumber#', '#Person4#', '#Email#', '#CardNumber#','#DateOfBirth#','#CarNumber#','#Person6#','#Person5#','#SSN#','#Person7#']\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"overwrite_output_dir\": True,\n",
    "        \"num_train_epochs\": 20,\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"per_device_train_batch_size\": 50,\n",
    "        \"per_device_eval_batch_size\": 32,\n",
    "        \"warmup_ratio\": 0.1,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"lr_scheduler_type\": 'cosine',\n",
    "        \"optim\": 'adamw_torch',\n",
    "        \"gradient_accumulation_steps\": 1,\n",
    "        \"evaluation_strategy\": 'epoch',\n",
    "        \"save_strategy\": 'epoch',\n",
    "        \"save_total_limit\": 5,\n",
    "        \"fp16\": True,\n",
    "        \"load_best_model_at_end\": True,\n",
    "        \"seed\": 42,\n",
    "        \"logging_dir\": \"./logs\",\n",
    "        \"logging_strategy\": \"epoch\",\n",
    "        \"predict_with_generate\": True,\n",
    "        \"generation_max_length\": 100,\n",
    "        \"do_train\": True,\n",
    "        \"do_eval\": True,\n",
    "        \"early_stopping_patience\": 3,\n",
    "        \"early_stopping_threshold\": 0.001,\n",
    "        \"report_to\": \"wandb\" # (ì„ íƒ) wandbë¥¼ ì‚¬ìš©í•  ë•Œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    },\n",
    "    # (ì„ íƒ) wandb í™ˆí˜ì´ì§€ì— ê°€ì…í•˜ì—¬ ì–»ì€ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.\n",
    "    # \"wandb\": {\n",
    "    #     \"entity\": \"up_ai_nlp_4\",\n",
    "    #     \"project\": \"Juyeong\",\n",
    "    #     \"name\": \"digit82\"\n",
    "    # },\n",
    "    \"inference\": {\n",
    "        \"ckt_path\": f\"/root/NLP/ckp/\", # ì‚¬ì „ í•™ìŠµì´ ì§„í–‰ëœ ëª¨ë¸ì˜ checkpointë¥¼ ë¶ˆëŸ¬ì˜¬ ê²½ë¡œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "        \"result_path\": \"./prediction/\",\n",
    "        \"no_repeat_ngram_size\": 15,\n",
    "        \"early_stopping\": True,\n",
    "        \"generate_max_length\": 100,\n",
    "        \"num_beams\": 6,\n",
    "        \"batch_size\" : 32,\n",
    "        \"repetition_penalty\" : 1.5, # ebanlee/kobart3\n",
    "        # ì •í™•í•œ ëª¨ë¸ í‰ê°€ë¥¼ ìœ„í•´ ì œê±°í•  ë¶ˆí•„ìš”í•œ ìƒì„± í† í°ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "        \"remove_tokens\": ['<usr>', f\"{tokenizer.bos_token}\", f\"{tokenizer.eos_token}\", f\"{tokenizer.pad_token}\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cm7ob25lHBkR"
   },
   "source": [
    "- ì°¸ê³ âœ…    \n",
    ": wandb ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„  entity, project, nameë¥¼ ì§€ì •í•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤. wandb í™ˆí˜ì´ì§€ì— ê°€ì…í•œ í›„ ì–»ì€ ì •ë³´ë¥¼ ì…ë ¥í•˜ì—¬ ì‘ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "id": "REJybO5UCabF"
   },
   "outputs": [],
   "source": [
    "# ëª¨ë¸ì˜ êµ¬ì„± ì •ë³´ë¥¼ YAML íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "config_path = \"/root/NLP/code/config.yaml\"\n",
    "with open(config_path, \"w\") as file:\n",
    "    yaml.dump(config_data, file, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObEASD6Wj6pl"
   },
   "source": [
    "### 3) Configuration ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JUBm_6RqlYpV",
    "outputId": "4b1c8c44-c6a9-40f1-adbd-72d48f0c983b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'general': {'data_path': '/root/NLP/data/',\n",
      "             'model_name': 'digit82/kobart-summarization',\n",
      "             'output_dir': './ckp/digit82/kobart-summarization/'},\n",
      " 'inference': {'batch_size': 32,\n",
      "               'ckt_path': '/root/NLP/ckp/',\n",
      "               'early_stopping': True,\n",
      "               'generate_max_length': 100,\n",
      "               'no_repeat_ngram_size': 15,\n",
      "               'num_beams': 6,\n",
      "               'remove_tokens': ['<usr>', '<s>', '</s>', '<pad>'],\n",
      "               'repetition_penalty': 1.5,\n",
      "               'result_path': './prediction/'},\n",
      " 'tokenizer': {'bos_token': '<s>',\n",
      "               'decoder_max_len': 100,\n",
      "               'encoder_max_len': 512,\n",
      "               'eos_token': '</s>',\n",
      "               'special_tokens': ['#Person1#',\n",
      "                                  '#Person2#',\n",
      "                                  '#Person3#',\n",
      "                                  '#PhoneNumber#',\n",
      "                                  '#Address#',\n",
      "                                  '#PassportNumber#',\n",
      "                                  '#Person4#',\n",
      "                                  '#Email#',\n",
      "                                  '#CardNumber#',\n",
      "                                  '#DateOfBirth#',\n",
      "                                  '#CarNumber#',\n",
      "                                  '#Person6#',\n",
      "                                  '#Person5#',\n",
      "                                  '#SSN#',\n",
      "                                  '#Person7#']},\n",
      " 'training': {'do_eval': True,\n",
      "              'do_train': True,\n",
      "              'early_stopping_patience': 3,\n",
      "              'early_stopping_threshold': 0.001,\n",
      "              'evaluation_strategy': 'epoch',\n",
      "              'fp16': True,\n",
      "              'generation_max_length': 100,\n",
      "              'gradient_accumulation_steps': 1,\n",
      "              'learning_rate': 1e-05,\n",
      "              'load_best_model_at_end': True,\n",
      "              'logging_dir': './logs',\n",
      "              'logging_strategy': 'epoch',\n",
      "              'lr_scheduler_type': 'cosine',\n",
      "              'num_train_epochs': 20,\n",
      "              'optim': 'adamw_torch',\n",
      "              'overwrite_output_dir': True,\n",
      "              'per_device_eval_batch_size': 32,\n",
      "              'per_device_train_batch_size': 50,\n",
      "              'predict_with_generate': True,\n",
      "              'report_to': 'wandb',\n",
      "              'save_strategy': 'epoch',\n",
      "              'save_total_limit': 5,\n",
      "              'seed': 42,\n",
      "              'warmup_ratio': 0.1,\n",
      "              'weight_decay': 0.01}}\n"
     ]
    }
   ],
   "source": [
    "# ì €ì¥ëœ config íŒŒì¼ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "config_path = \"/root/NLP/code/config.yaml\"\n",
    "\n",
    "with open(config_path, \"r\") as file:\n",
    "    loaded_config = yaml.safe_load(file)\n",
    "\n",
    "# ë¶ˆëŸ¬ì˜¨ config íŒŒì¼ì˜ ì „ì²´ ë‚´ìš©ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "pprint(loaded_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xRSbKEVslhwO",
    "outputId": "40ba5c67-574e-4f86-cbac-13e9f01c588a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_path': '/root/NLP/data/',\n",
       " 'model_name': 'digit82/kobart-summarization',\n",
       " 'output_dir': './ckp/digit82/kobart-summarization/'}"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì‹¤í—˜ì— ì“°ì¼ ë°ì´í„°ì˜ ê²½ë¡œ, ì‚¬ìš©ë  ëª¨ë¸, ëª¨ë¸ì˜ ìµœì¢… ì¶œë ¥ ê²°ê³¼ë¥¼ ì €ì¥í•  ê²½ë¡œì— ëŒ€í•´ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "loaded_config['general']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ê³³ì— ì‚¬ìš©ìê°€ ì €ì¥í•œ ë°ì´í„° dir ì„¤ì •í•˜ê¸°\n",
    "loaded_config['general']['data_path'] = \"data_path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1pvFmIOqljv1",
    "outputId": "958c9b06-90de-4872-b2fb-cf739a655b4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<s>',\n",
       " 'decoder_max_len': 100,\n",
       " 'encoder_max_len': 512,\n",
       " 'eos_token': '</s>',\n",
       " 'special_tokens': ['#Person1#',\n",
       "  '#Person2#',\n",
       "  '#Person3#',\n",
       "  '#PhoneNumber#',\n",
       "  '#Address#',\n",
       "  '#PassportNumber#',\n",
       "  '#Person4#',\n",
       "  '#Email#',\n",
       "  '#CardNumber#',\n",
       "  '#DateOfBirth#',\n",
       "  '#CarNumber#',\n",
       "  '#Person6#',\n",
       "  '#Person5#',\n",
       "  '#SSN#',\n",
       "  '#Person7#']}"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ í•˜ê¸° ìœ„í•´ tokenization ê³¼ì •ì—ì„œ í•„ìš”í•œ ì •ë³´ë“¤ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "loaded_config['tokenizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MEvwCIBVll-h",
    "outputId": "ca010ac3-05be-4983-d665-2a653f0ced0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'do_eval': True,\n",
       " 'do_train': True,\n",
       " 'early_stopping_patience': 3,\n",
       " 'early_stopping_threshold': 0.001,\n",
       " 'evaluation_strategy': 'epoch',\n",
       " 'fp16': True,\n",
       " 'generation_max_length': 100,\n",
       " 'gradient_accumulation_steps': 1,\n",
       " 'learning_rate': 1e-05,\n",
       " 'load_best_model_at_end': True,\n",
       " 'logging_dir': './logs',\n",
       " 'logging_strategy': 'epoch',\n",
       " 'lr_scheduler_type': 'cosine',\n",
       " 'num_train_epochs': 20,\n",
       " 'optim': 'adamw_torch',\n",
       " 'overwrite_output_dir': True,\n",
       " 'per_device_eval_batch_size': 32,\n",
       " 'per_device_train_batch_size': 50,\n",
       " 'predict_with_generate': True,\n",
       " 'report_to': 'wandb',\n",
       " 'save_strategy': 'epoch',\n",
       " 'save_total_limit': 5,\n",
       " 'seed': 42,\n",
       " 'warmup_ratio': 0.1,\n",
       " 'weight_decay': 0.01}"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ëª¨ë¸ì´ í›ˆë ¨ ì‹œ ì ìš©ë  ë§¤ê°œë³€ìˆ˜ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "loaded_config['training']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xhqHf1njlnyg",
    "outputId": "be9519c6-118b-4e4f-ea11-4bcca0ac42bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entity': 'up_ai_nlp_4', 'name': 'digit82', 'project': 'Juyeong'}"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # ëª¨ë¸ í•™ìŠµ ê³¼ì •ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ëŠ” wandb ì„¤ì • ë‚´ìš©ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "# loaded_config['wandb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # (ì„ íƒ) ì´ê³³ì— ì‚¬ìš©ìê°€ ì‚¬ìš©í•  wandb config ì„¤ì •\n",
    "# loaded_config['wandb']['entity'] = \"up_ai_nlp_4\"\n",
    "# loaded_config['wandb']['name'] = \"digit82_aug_bt\"\n",
    "# loaded_config['wandb']['project'] = \"Juyeong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fm4gxPRVlppj",
    "outputId": "1342aa36-3934-4f73-c912-e7d35fe6df06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32,\n",
       " 'ckt_path': '/root/NLP/ckp/',\n",
       " 'early_stopping': True,\n",
       " 'generate_max_length': 100,\n",
       " 'no_repeat_ngram_size': 15,\n",
       " 'num_beams': 6,\n",
       " 'remove_tokens': ['<usr>', '<s>', '</s>', '<pad>'],\n",
       " 'repetition_penalty': 1.5,\n",
       " 'result_path': './prediction/'}"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ëª¨ë¸ì´ ìµœì¢… ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ê¸° ìœ„í•œ ë§¤ê°œë³€ìˆ˜ ì •ë³´ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "loaded_config['inference']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2zt0b-8ogCL"
   },
   "source": [
    "### 4) ë°ì´í„° ë¶ˆëŸ¬ì™€ì„œ í™•ì¸í•´ë³´ê¸°\n",
    "- ì‹¤í—˜ì—ì„œ ì“°ì¼ ë°ì´í„°ë¥¼ loadí•˜ì—¬ ë°ì´í„°ì˜ êµ¬ì¡°ì™€ ë‚´ìš©ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "- Train, dev, test ìˆœì„œëŒ€ë¡œ 12457, 499, 250ê°œ ì”© ë°ì´í„°ê°€ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "QFHIE2G04y-K",
    "outputId": "19312d21-f5bf-495f-c626-cc17b82024a4"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data_path/pseu_sum_aug_bt.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[282], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m data_path \u001b[38;5;241m=\u001b[39m loaded_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneral\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_path\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# train dataì˜ êµ¬ì¡°ì™€ ë‚´ìš©ì„ í™•ì¸í•©ë‹ˆë‹¤.\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m train_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpseu_sum_aug_bt.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m train_df\u001b[38;5;241m.\u001b[39mtail()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data_path/pseu_sum_aug_bt.csv'"
     ]
    }
   ],
   "source": [
    "# configì— ì €ì¥ëœ ë°ì´í„° ê²½ë¡œë¥¼ í†µí•´ trainê³¼ validation dataë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "data_path = loaded_config['general']['data_path']\n",
    "\n",
    "# train dataì˜ êµ¬ì¡°ì™€ ë‚´ìš©ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "train_df = pd.read_csv(os.path.join(data_path, 'pseu_sum_aug_bt.csv'))\n",
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "FAGaYvNZ09Sq",
    "outputId": "bf8bf286-19e7-469d-ffae-41e6ad795ae6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>dev_495</td>\n",
       "      <td>#Person1#: ì´ì œ ìƒˆí•´ê°€ ë˜ì–´ì„œ ìƒˆë¡œìš´ ì‹œì‘ì„ í•˜ë ¤ê³  ê²°ì‹¬í–ˆì–´. \\r\\n#P...</td>\n",
       "      <td>#Person1#ì€ ìƒˆí•´ì— ê¸ˆì—°ì„ í•˜ê³  ì»¤ë°ì•„ì›ƒí•˜ê¸°ë¡œ ê²°ì •í–ˆìŠµë‹ˆë‹¤. #Person2...</td>\n",
       "      <td>ìƒˆí•´</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>dev_496</td>\n",
       "      <td>#Person1#: ë„ˆ, ì¡°ë‘ ê²°í˜¼í–ˆì§€? \\r\\n#Person2#: ì¡°? ë¬´ìŠ¨ ë§ì¸...</td>\n",
       "      <td>#Person1#ì€ #Person2#ê°€ ì¡°ì™€ ê²°í˜¼í–ˆë‹¤ê³  ìƒê°í–ˆë‹¤. #Person2#...</td>\n",
       "      <td>ì‚¬ë‘ì— ë¹ ì§€ë‹¤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>dev_497</td>\n",
       "      <td>#Person1#: ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”, ë¶€ì¸?\\r\\n#Person2#: ëª‡ ì£¼ ë™...</td>\n",
       "      <td>#Person2#ì˜ ì°¨ì—ì„œ ì´ìƒí•œ ì†Œë¦¬ê°€ ë‚©ë‹ˆë‹¤. #Person1#ëŠ” ë¸Œë ˆì´í¬ë¥¼ êµ...</td>\n",
       "      <td>ì†ŒìŒ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>dev_498</td>\n",
       "      <td>#Person1#: ì•ˆë…•í•˜ì„¸ìš”, ì•„ë§ˆì¡´ ê³ ê° ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\\n...</td>\n",
       "      <td>#Person2#ë‹˜ì´ ì•„ë§ˆì¡´ ê³ ê° ì„œë¹„ìŠ¤ì— ì „í™”í•˜ì—¬ ì•„ë§ˆì¡´ì—ì„œ ë°›ì€ ì±…ì— í•œ í˜ì´ì§€...</td>\n",
       "      <td>ë¹ ì§„ í˜ì´ì§€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>dev_499</td>\n",
       "      <td>#Person1#: ì—¬ë¦„ì´ ë‹¤ ë˜ì–´ê°„ë‹¤ëŠ” ê²Œ ë¯¿ê¸°ì§€ ì•Šì•„.\\r\\n#Person2#:...</td>\n",
       "      <td>#Person2#ëŠ” #Person1#ì—ê²Œ ì—¬ë¦„ íœ´ê°€ ë™ì•ˆ íŒŒí‹°ë¥¼ ë„ì™€ì£¼ëŠ” íšŒì‚¬ì—ì„œ ...</td>\n",
       "      <td>ì—¬ë¦„ íœ´ê°€</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fname                                           dialogue  \\\n",
       "494  dev_495  #Person1#: ì´ì œ ìƒˆí•´ê°€ ë˜ì–´ì„œ ìƒˆë¡œìš´ ì‹œì‘ì„ í•˜ë ¤ê³  ê²°ì‹¬í–ˆì–´. \\r\\n#P...   \n",
       "495  dev_496  #Person1#: ë„ˆ, ì¡°ë‘ ê²°í˜¼í–ˆì§€? \\r\\n#Person2#: ì¡°? ë¬´ìŠ¨ ë§ì¸...   \n",
       "496  dev_497  #Person1#: ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”, ë¶€ì¸?\\r\\n#Person2#: ëª‡ ì£¼ ë™...   \n",
       "497  dev_498  #Person1#: ì•ˆë…•í•˜ì„¸ìš”, ì•„ë§ˆì¡´ ê³ ê° ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\\n...   \n",
       "498  dev_499  #Person1#: ì—¬ë¦„ì´ ë‹¤ ë˜ì–´ê°„ë‹¤ëŠ” ê²Œ ë¯¿ê¸°ì§€ ì•Šì•„.\\r\\n#Person2#:...   \n",
       "\n",
       "                                               summary    topic  \n",
       "494  #Person1#ì€ ìƒˆí•´ì— ê¸ˆì—°ì„ í•˜ê³  ì»¤ë°ì•„ì›ƒí•˜ê¸°ë¡œ ê²°ì •í–ˆìŠµë‹ˆë‹¤. #Person2...       ìƒˆí•´  \n",
       "495  #Person1#ì€ #Person2#ê°€ ì¡°ì™€ ê²°í˜¼í–ˆë‹¤ê³  ìƒê°í–ˆë‹¤. #Person2#...  ì‚¬ë‘ì— ë¹ ì§€ë‹¤  \n",
       "496  #Person2#ì˜ ì°¨ì—ì„œ ì´ìƒí•œ ì†Œë¦¬ê°€ ë‚©ë‹ˆë‹¤. #Person1#ëŠ” ë¸Œë ˆì´í¬ë¥¼ êµ...       ì†ŒìŒ  \n",
       "497  #Person2#ë‹˜ì´ ì•„ë§ˆì¡´ ê³ ê° ì„œë¹„ìŠ¤ì— ì „í™”í•˜ì—¬ ì•„ë§ˆì¡´ì—ì„œ ë°›ì€ ì±…ì— í•œ í˜ì´ì§€...   ë¹ ì§„ í˜ì´ì§€  \n",
       "498  #Person2#ëŠ” #Person1#ì—ê²Œ ì—¬ë¦„ íœ´ê°€ ë™ì•ˆ íŒŒí‹°ë¥¼ ë„ì™€ì£¼ëŠ” íšŒì‚¬ì—ì„œ ...    ì—¬ë¦„ íœ´ê°€  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation dataì˜ êµ¬ì¡°ì™€ ë‚´ìš©ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "val_df = pd.read_csv(os.path.join(data_path,'dev.csv'))\n",
    "val_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NaN ê°’ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ëŒ€ì²´\n",
    "train_df['summary'] = train_df['summary'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëŒ€í™” ê¸¸ì´ì— ëŒ€í•œ ì •ë³´\n",
      "count    29412.000000\n",
      "mean       436.550626\n",
      "std        219.534864\n",
      "min         55.000000\n",
      "25%        297.000000\n",
      "50%        394.000000\n",
      "75%        537.000000\n",
      "max       2895.000000\n",
      "Name: dialogue, dtype: float64\n",
      "=================\n",
      "ìš”ì•½ë¬¸ ê¸¸ì´ì— ëŒ€í•œ ì •ë³´\n",
      "count    29412.000000\n",
      "mean        84.439650\n",
      "std         35.410706\n",
      "min          0.000000\n",
      "25%         59.000000\n",
      "50%         78.000000\n",
      "75%        102.000000\n",
      "max        451.000000\n",
      "Name: summary, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# dialog ì™€ summary ê°ê°ì˜ ëª¨ë¸ max_length ì„¤ì •ì„ ìœ„í•œ ê¸¸ì´ í™•ì¸\n",
    "\n",
    "train_dialog_length = train_df['dialogue'].apply(lambda x:len(x))\n",
    "train_summary_length = train_df['summary'].apply(lambda x:len(x))\n",
    "\n",
    "print(\"ëŒ€í™” ê¸¸ì´ì— ëŒ€í•œ ì •ë³´\")\n",
    "print(train_dialog_length.describe())\n",
    "print(\"=================\")\n",
    "print(\"ìš”ì•½ë¬¸ ê¸¸ì´ì— ëŒ€í•œ ì •ë³´\")\n",
    "print(train_summary_length.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëŒ€í™” ê¸¸ì´ì— ëŒ€í•œ ì •ë³´\n",
      "count    499.000000\n",
      "mean     203.657315\n",
      "std       93.754404\n",
      "min       58.000000\n",
      "25%      142.000000\n",
      "50%      187.000000\n",
      "75%      249.500000\n",
      "max      765.000000\n",
      "Name: dialogue, dtype: float64\n",
      "=================\n",
      "ìš”ì•½ë¬¸ ê¸¸ì´ì— ëŒ€í•œ ì •ë³´\n",
      "count    499.000000\n",
      "mean      38.639279\n",
      "std       16.452748\n",
      "min       11.000000\n",
      "25%       27.000000\n",
      "50%       35.000000\n",
      "75%       46.000000\n",
      "max      116.000000\n",
      "Name: summary, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "len_train_df = pd.read_csv(os.path.join('/root/NLP/data/','dev.csv'))\n",
    "\n",
    "# tokenized = tokenizer(text_df, padding=True)\n",
    "\n",
    "train_dialog_length = len_train_df['dialogue'].apply(lambda x:len(tokenizer(x, padding= True)['input_ids']))\n",
    "train_summary_length = len_train_df['summary'].apply(lambda x:len(tokenizer(x, padding= True)['input_ids']))\n",
    "\n",
    "\n",
    "print(\"ëŒ€í™” ê¸¸ì´ì— ëŒ€í•œ ì •ë³´\")\n",
    "print(train_dialog_length.describe())\n",
    "print(\"=================\")\n",
    "print(\"ìš”ì•½ë¬¸ ê¸¸ì´ì— ëŒ€í•œ ì •ë³´\")\n",
    "print(train_summary_length.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IIaIrpH4kWo"
   },
   "source": [
    "## 1. ë°ì´í„° ê°€ê³µ ë° ë°ì´í„°ì…‹ í´ë˜ìŠ¤ êµ¬ì¶•\n",
    "- csv file ì„ ë¶ˆëŸ¬ì™€ì„œ encoder ì™€ decoderì˜ ì…ë ¥í˜•íƒœë¡œ ê°€ê³µí•´ì¤ë‹ˆë‹¤.\n",
    "- ê°€ê³µëœ ë°ì´í„°ë¥¼ torch dataset class ë¡œ êµ¬ì¶•í•˜ì—¬ ëª¨ë¸ì— ì…ë ¥ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë§Œë“­ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "id": "oWPawUUflwHa"
   },
   "outputs": [],
   "source": [
    "# ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ í´ë˜ìŠ¤ë¡œ, ë°ì´í„°ì…‹ì„ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì¸ì½”ë”ì™€ ë””ì½”ë”ì˜ ì…ë ¥ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "class Preprocess:\n",
    "    def __init__(self,\n",
    "            bos_token: str,\n",
    "            eos_token: str,\n",
    "        ) -> None:\n",
    "\n",
    "        self.bos_token = bos_token\n",
    "        self.eos_token = eos_token\n",
    "\n",
    "    @staticmethod\n",
    "    # ì‹¤í—˜ì— í•„ìš”í•œ ì»¬ëŸ¼ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "    def make_set_as_df(file_path, is_train = True):\n",
    "        if is_train:\n",
    "            df = pd.read_csv(file_path)\n",
    "            train_df = df[['fname','dialogue','summary']]\n",
    "            return train_df\n",
    "        else:\n",
    "            df = pd.read_csv(file_path)\n",
    "            test_df = df[['fname','dialogue']]\n",
    "            return test_df\n",
    "\n",
    "    # BART ëª¨ë¸ì˜ ì…ë ¥, ì¶œë ¥ í˜•íƒœë¥¼ ë§ì¶”ê¸° ìœ„í•´ ì „ì²˜ë¦¬ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "    def make_input(self, dataset,is_test = False):\n",
    "        if is_test:\n",
    "            encoder_input = dataset['dialogue']\n",
    "            decoder_input = [self.bos_token] * len(dataset['dialogue'])\n",
    "            return encoder_input.tolist(), list(decoder_input)\n",
    "        else:\n",
    "            encoder_input = dataset['dialogue']\n",
    "            decoder_input = dataset['summary'].apply(lambda x : self.bos_token + str(x)) # Ground truthë¥¼ ë””ì½”ë”ì˜ inputìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "            decoder_output = dataset['summary'].apply(lambda x : str(x) + self.eos_token)\n",
    "            return encoder_input.tolist(), decoder_input.tolist(), decoder_output.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "id": "6GDvodoF8sED"
   },
   "outputs": [],
   "source": [
    "# Trainì— ì‚¬ìš©ë˜ëŠ” Dataset í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "class DatasetForTrain(Dataset):\n",
    "    def __init__(self, encoder_input, decoder_input, labels, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.decoder_input = decoder_input\n",
    "        self.labels = labels\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()} # item[input_ids], item[attention_mask]\n",
    "        item2 = {key: val[idx].clone().detach() for key, val in self.decoder_input.items()} # item2[input_ids], item2[attention_mask]\n",
    "        item2['decoder_input_ids'] = item2['input_ids']\n",
    "        item2['decoder_attention_mask'] = item2['attention_mask']\n",
    "        item2.pop('input_ids')\n",
    "        item2.pop('attention_mask')\n",
    "        item.update(item2) #item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask]\n",
    "        item['labels'] = self.labels['input_ids'][idx] #item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask], item[labels]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Validationì— ì‚¬ìš©ë˜ëŠ” Dataset í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "class DatasetForVal(Dataset):\n",
    "    def __init__(self, encoder_input, decoder_input, labels, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.decoder_input = decoder_input\n",
    "        self.labels = labels\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()} # item[input_ids], item[attention_mask]\n",
    "        item2 = {key: val[idx].clone().detach() for key, val in self.decoder_input.items()} # item2[input_ids], item2[attention_mask]\n",
    "        item2['decoder_input_ids'] = item2['input_ids']\n",
    "        item2['decoder_attention_mask'] = item2['attention_mask']\n",
    "        item2.pop('input_ids')\n",
    "        item2.pop('attention_mask')\n",
    "        item.update(item2) #item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask]\n",
    "        item['labels'] = self.labels['input_ids'][idx] #item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask], item[labels]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Testì— ì‚¬ìš©ë˜ëŠ” Dataset í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "class DatasetForInference(Dataset):\n",
    "    def __init__(self, encoder_input, test_id, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.test_id = test_id\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()}\n",
    "        item['ID'] = self.test_id[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_token_lengths(tokenized_inputs, name=\"\"):\n",
    "    lengths = [len(ids) for ids in tokenized_inputs['input_ids']]\n",
    "    \n",
    "    print(f\"\\n{name} í† í° ê¸¸ì´ ë¶„ì„:\")\n",
    "    print(f\"í‰ê·  ê¸¸ì´: {sum(lengths)/len(lengths):.2f}\")\n",
    "    print(f\"ìµœëŒ€ ê¸¸ì´: {max(lengths)}\")\n",
    "    print(f\"ìµœì†Œ ê¸¸ì´: {min(lengths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "id": "hT9z4vvS2CCb"
   },
   "outputs": [],
   "source": [
    "# tokenization ê³¼ì •ê¹Œì§€ ì§„í–‰ëœ ìµœì¢…ì ìœ¼ë¡œ ëª¨ë¸ì— ì…ë ¥ë  ë°ì´í„°ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "def prepare_train_dataset(config, preprocessor, data_path, tokenizer):\n",
    "    train_file_path = os.path.join(data_path,'train.csv')\n",
    "    val_file_path = os.path.join(data_path,'dev.csv')\n",
    "\n",
    "    # train, validationì— ëŒ€í•´ ê°ê° ë°ì´í„°í”„ë ˆì„ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.\n",
    "    train_data = preprocessor.make_set_as_df(train_file_path)\n",
    "    val_data = preprocessor.make_set_as_df(val_file_path)\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f'train_data:\\n {train_data[\"dialogue\"][0]}')\n",
    "    print(f'train_label:\\n {train_data[\"summary\"][0]}')\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f'val_data:\\n {val_data[\"dialogue\"][0]}')\n",
    "    print(f'val_label:\\n {val_data[\"summary\"][0]}')\n",
    "\n",
    "    encoder_input_train , decoder_input_train, decoder_output_train = preprocessor.make_input(train_data)\n",
    "    encoder_input_val , decoder_input_val, decoder_output_val = preprocessor.make_input(val_data)\n",
    "    print('-'*10, 'Load data complete', '-'*10,)\n",
    "\n",
    "    tokenized_encoder_inputs = tokenizer(encoder_input_train, return_tensors=\"pt\", padding=True,\n",
    "                            add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False)\n",
    "    tokenized_decoder_inputs = tokenizer(decoder_input_train, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "    tokenized_decoder_ouputs = tokenizer(decoder_output_train, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "\n",
    "    train_inputs_dataset = DatasetForTrain(tokenized_encoder_inputs, tokenized_decoder_inputs, tokenized_decoder_ouputs,len(encoder_input_train))\n",
    "\n",
    "    val_tokenized_encoder_inputs = tokenizer(encoder_input_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False)\n",
    "    val_tokenized_decoder_inputs = tokenizer(decoder_input_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "    val_tokenized_decoder_ouputs = tokenizer(decoder_output_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "\n",
    "    val_inputs_dataset = DatasetForVal(val_tokenized_encoder_inputs, val_tokenized_decoder_inputs, val_tokenized_decoder_ouputs,len(encoder_input_val))\n",
    "\n",
    "    print('-'*10, 'Make dataset complete', '-'*10,)\n",
    "    \n",
    "    # í† í° ê¸¸ì´ í™•ì¸\n",
    "    analyze_token_lengths(tokenized_encoder_inputs, \"Encoder Input\")\n",
    "    analyze_token_lengths(tokenized_decoder_inputs, \"Decoder Input\")\n",
    "    analyze_token_lengths(tokenized_decoder_ouputs, \"Decoder Output\")\n",
    "\n",
    "    return train_inputs_dataset, val_inputs_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5sKIJ5K5Pz1"
   },
   "source": [
    "## 2. Trainer ë° Trainingargs êµ¬ì¶•í•˜ê¸°\n",
    "- Huggingface ì˜ Trainer ì™€ Training argumentsë¥¼ í™œìš©í•˜ì—¬ ëª¨ë¸ í•™ìŠµì„ ì¼ê´„ì ìœ¼ë¡œ ì²˜ë¦¬í•´ì£¼ëŠ” í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "id": "aQk8ILcEeGNz"
   },
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ì„±ëŠ¥ì— ëŒ€í•œ í‰ê°€ ì§€í‘œë¥¼ ì •ì˜í•©ë‹ˆë‹¤. ë³¸ ëŒ€íšŒì—ì„œëŠ” ROUGE ì ìˆ˜ë¥¼ í†µí•´ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.\n",
    "def compute_metrics(config,tokenizer,pred):\n",
    "    rouge = Rouge()\n",
    "    predictions = pred.predictions\n",
    "    labels = pred.label_ids\n",
    "\n",
    "    predictions[predictions == -100] = tokenizer.pad_token_id\n",
    "    labels[labels == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, clean_up_tokenization_spaces=True)\n",
    "    labels = tokenizer.batch_decode(labels, clean_up_tokenization_spaces=True)\n",
    "\n",
    "    # ì •í™•í•œ í‰ê°€ë¥¼ ìœ„í•´ ë¯¸ë¦¬ ì •ì˜ëœ ë¶ˆí•„ìš”í•œ ìƒì„±í† í°ë“¤ì„ ì œê±°í•©ë‹ˆë‹¤.\n",
    "    replaced_predictions = decoded_preds.copy()\n",
    "    replaced_labels = labels.copy()\n",
    "    remove_tokens = config['inference']['remove_tokens']\n",
    "    for token in remove_tokens:\n",
    "        replaced_predictions = [sentence.replace(token,\" \") for sentence in replaced_predictions]\n",
    "        replaced_labels = [sentence.replace(token,\" \") for sentence in replaced_labels]\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f\"PRED: {replaced_predictions[0]}\")\n",
    "    print(f\"GOLD: {replaced_labels[0]}\")\n",
    "    print('-'*150)\n",
    "    print(f\"PRED: {replaced_predictions[1]}\")\n",
    "    print(f\"GOLD: {replaced_labels[1]}\")\n",
    "    print('-'*150)\n",
    "    print(f\"PRED: {replaced_predictions[2]}\")\n",
    "    print(f\"GOLD: {replaced_labels[2]}\")\n",
    "\n",
    "    # ìµœì¢…ì ì¸ ROUGE ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "    results = rouge.get_scores(replaced_predictions, replaced_labels,avg=True)\n",
    "\n",
    "    # ROUGE ì ìˆ˜ ì¤‘ F-1 scoreë¥¼ í†µí•´ í‰ê°€í•©ë‹ˆë‹¤.\n",
    "    result = {key: value[\"f\"] for key, value in results.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "id": "RInkG8g-HjBi"
   },
   "outputs": [],
   "source": [
    "# í•™ìŠµì„ ìœ„í•œ trainer í´ë˜ìŠ¤ì™€ ë§¤ê°œë³€ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "def load_trainer_for_train(config,generate_model,tokenizer,train_inputs_dataset,val_inputs_dataset):\n",
    "    print('-'*10, 'Make training arguments', '-'*10,)\n",
    "    # set training args\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "                output_dir=config['general']['output_dir'], # model output directory\n",
    "                overwrite_output_dir=config['training']['overwrite_output_dir'],\n",
    "                num_train_epochs=config['training']['num_train_epochs'],  # total number of training epochs\n",
    "                learning_rate=config['training']['learning_rate'], # learning_rate\n",
    "                per_device_train_batch_size=config['training']['per_device_train_batch_size'], # batch size per device during training\n",
    "                per_device_eval_batch_size=config['training']['per_device_eval_batch_size'],# batch size for evaluation\n",
    "                warmup_ratio=config['training']['warmup_ratio'],  # number of warmup steps for learning rate scheduler\n",
    "                weight_decay=config['training']['weight_decay'],  # strength of weight decay\n",
    "                lr_scheduler_type=config['training']['lr_scheduler_type'],\n",
    "                optim =config['training']['optim'],\n",
    "                gradient_accumulation_steps=config['training']['gradient_accumulation_steps'],\n",
    "                evaluation_strategy=config['training']['evaluation_strategy'], # evaluation strategy to adopt during training\n",
    "                save_strategy =config['training']['save_strategy'],\n",
    "                save_total_limit=config['training']['save_total_limit'], # number of total save model.\n",
    "                fp16=config['training']['fp16'],\n",
    "                load_best_model_at_end=config['training']['load_best_model_at_end'], # ìµœì¢…ì ìœ¼ë¡œ ê°€ì¥ ë†’ì€ ì ìˆ˜ ì €ì¥\n",
    "                seed=config['training']['seed'],\n",
    "                logging_dir=config['training']['logging_dir'], # directory for storing logs\n",
    "                logging_strategy=config['training']['logging_strategy'],\n",
    "                predict_with_generate=config['training']['predict_with_generate'], #To use BLEU or ROUGE score\n",
    "                generation_max_length=config['training']['generation_max_length'],\n",
    "                do_train=config['training']['do_train'],\n",
    "                do_eval=config['training']['do_eval'],\n",
    "                # report_to=config['training']['report_to'] # (ì„ íƒ) wandbë¥¼ ì‚¬ìš©í•  ë•Œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "            )\n",
    "\n",
    "\n",
    "    # # # (ì„ íƒ) ëª¨ë¸ checkpointë¥¼ wandbì— ì €ì¥í•˜ë„ë¡ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    # os.environ[\"WANDB_LOG_MODEL\"]=\"true\"\n",
    "    # os.environ[\"WANDB_WATCH\"]=\"false\"\n",
    "\n",
    "\n",
    "    # # # (ì„ íƒ) ëª¨ë¸ì˜ í•™ìŠµ ê³¼ì •ì„ ì¶”ì í•˜ëŠ” wandbë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì´ˆê¸°í™” í•´ì¤ë‹ˆë‹¤.\n",
    "    # wandb.init(\n",
    "    #     entity=config['wandb']['entity'],\n",
    "    #     project=config['wandb']['project'],\n",
    "    #     name=config['wandb']['name'],\n",
    "    # )\n",
    "    \n",
    "    # Validation lossê°€ ë” ì´ìƒ ê°œì„ ë˜ì§€ ì•Šì„ ë•Œ í•™ìŠµì„ ì¤‘ë‹¨ì‹œí‚¤ëŠ” EarlyStopping ê¸°ëŠ¥ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    MyCallback = EarlyStoppingCallback(\n",
    "        early_stopping_patience=config['training']['early_stopping_patience'],\n",
    "        early_stopping_threshold=config['training']['early_stopping_threshold']\n",
    "    )\n",
    "    print('-'*10, 'Make training arguments complete', '-'*10,)\n",
    "    print('-'*10, 'Make trainer', '-'*10,)\n",
    "\n",
    "    # Trainer í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=generate_model, # ì‚¬ìš©ìê°€ ì‚¬ì „ í•™ìŠµí•˜ê¸° ìœ„í•´ ì‚¬ìš©í•  ëª¨ë¸ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n",
    "        args=training_args,\n",
    "        train_dataset=train_inputs_dataset,\n",
    "        eval_dataset=val_inputs_dataset,\n",
    "        compute_metrics = lambda pred: compute_metrics(config,tokenizer, pred),\n",
    "        callbacks = [MyCallback]\n",
    "    )\n",
    "    print('-'*10, 'Make trainer complete', '-'*10,)\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "id": "KKWHe8dE5fSx"
   },
   "outputs": [],
   "source": [
    "# í•™ìŠµì„ ìœ„í•œ tokenizerì™€ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "def load_tokenizer_and_model_for_train(config,device):\n",
    "    print('-'*10, 'Load tokenizer & model', '-'*10,)\n",
    "    print('-'*10, f'Model Name : {config[\"general\"][\"model_name\"]}', '-'*10,)\n",
    "    model_name = config['general']['model_name']\n",
    "    bart_config = BartConfig().from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    generate_model = BartForConditionalGeneration.from_pretrained(config['general']['model_name'],config=bart_config)\n",
    "\n",
    "    special_tokens_dict={'additional_special_tokens':config['tokenizer']['special_tokens']}\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "    generate_model.resize_token_embeddings(len(tokenizer)) # ì‚¬ì „ì— special tokenì„ ì¶”ê°€í–ˆìœ¼ë¯€ë¡œ ì¬êµ¬ì„± í•´ì¤ë‹ˆë‹¤.\n",
    "    generate_model.to(device)\n",
    "    print(generate_model.config)\n",
    "\n",
    "    print('-'*10, 'Load tokenizer & model complete', '-'*10,)\n",
    "    return generate_model , tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvutzKQYvQgl"
   },
   "source": [
    "## 3. ëª¨ë¸ í•™ìŠµí•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImZUb-BC42J-"
   },
   "source": [
    "- ì•ì—ì„œ êµ¬ì¶•í•œ í´ë˜ìŠ¤ ë° í•¨ìˆ˜ë¥¼ í™œìš©í•˜ì—¬ í•™ìŠµ ì§„í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "id": "qnA96wmR44is"
   },
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    # ì‚¬ìš©í•  deviceë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
    "    print('-'*10, f'device : {device}', '-'*10,)\n",
    "    print(torch.__version__)\n",
    "\n",
    "    # ì‚¬ìš©í•  ëª¨ë¸ê³¼ tokenizerë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "    generate_model , tokenizer = load_tokenizer_and_model_for_train(config,device)\n",
    "    print('-'*10,\"tokenizer special tokens : \",tokenizer.special_tokens_map,'-'*10)\n",
    "\n",
    "    # í•™ìŠµì— ì‚¬ìš©í•  ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "    preprocessor = Preprocess(config['tokenizer']['bos_token'], config['tokenizer']['eos_token']) # decoder_start_token: str, eos_token: str\n",
    "    data_path = config['general']['data_path']\n",
    "    train_inputs_dataset, val_inputs_dataset = prepare_train_dataset(config,preprocessor, data_path, tokenizer)\n",
    "\n",
    "    # Trainer í´ë˜ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "    trainer = load_trainer_for_train(config, generate_model,tokenizer,train_inputs_dataset,val_inputs_dataset)\n",
    "    trainer.train()   # ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
    "\n",
    "    # # (ì„ íƒ) ëª¨ë¸ í•™ìŠµì´ ì™„ë£Œëœ í›„ wandbë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\n",
    "    # wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!rm -rf wandb/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aborted!\n"
     ]
    }
   ],
   "source": [
    "!wandb login --relogin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1DMS60wL-Dhv",
    "outputId": "cbb6aba7-18ff-4d12-b9e7-2a2ef31d94d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- device : cuda:0 ----------\n",
      "2.1.0\n",
      "---------- Load tokenizer & model ----------\n",
      "---------- Model Name : digit82/kobart-summarization ----------\n",
      "BartConfig {\n",
      "  \"_name_or_path\": \"digit82/kobart-summarization\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.1,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 1026,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30015\n",
      "}\n",
      "\n",
      "---------- Load tokenizer & model complete ----------\n",
      "---------- tokenizer special tokens :  {'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'mask_token': '<mask>', 'additional_special_tokens': ['#Email#', '#Person5#', '#DateOfBirth#', '#SSN#', '#CarNumber#', '#PassportNumber#', '#Person2#', '#CardNumber#', '#Address#', '#Person7#', '#Person1#', '#Person6#', '#Person4#', '#PhoneNumber#', '#Person3#']} ----------\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "train_data:\n",
      " #Person1#: ì•ˆë…•í•˜ì„¸ìš”, ìŠ¤ë¯¸ìŠ¤ì”¨. ì €ëŠ” í˜¸í‚¨ìŠ¤ ì˜ì‚¬ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ ì™œ ì˜¤ì…¨ë‚˜ìš”?\n",
      "#Person2#: ê±´ê°•ê²€ì§„ì„ ë°›ëŠ” ê²ƒì´ ì¢‹ì„ ê²ƒ ê°™ì•„ì„œìš”.\n",
      "#Person1#: ê·¸ë ‡êµ°ìš”, ë‹¹ì‹ ì€ 5ë…„ ë™ì•ˆ ê±´ê°•ê²€ì§„ì„ ë°›ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë§¤ë…„ ë°›ì•„ì•¼ í•©ë‹ˆë‹¤.\n",
      "#Person2#: ì•Œê³  ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì•„ë¬´ ë¬¸ì œê°€ ì—†ë‹¤ë©´ ì™œ ì˜ì‚¬ë¥¼ ë§Œë‚˜ëŸ¬ ê°€ì•¼ í•˜ë‚˜ìš”?\n",
      "#Person1#: ì‹¬ê°í•œ ì§ˆë³‘ì„ í”¼í•˜ëŠ” ê°€ì¥ ì¢‹ì€ ë°©ë²•ì€ ì´ë¥¼ ì¡°ê¸°ì— ë°œê²¬í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‹ˆ ë‹¹ì‹ ì˜ ê±´ê°•ì„ ìœ„í•´ ìµœì†Œí•œ ë§¤ë…„ í•œ ë²ˆì€ ì˜¤ì„¸ìš”.\n",
      "#Person2#: ì•Œê² ìŠµë‹ˆë‹¤.\n",
      "#Person1#: ì—¬ê¸° ë³´ì„¸ìš”. ë‹¹ì‹ ì˜ ëˆˆê³¼ ê·€ëŠ” ê´œì°®ì•„ ë³´ì…ë‹ˆë‹¤. ê¹Šê²Œ ìˆ¨ì„ ë“¤ì´ì‰¬ì„¸ìš”. ìŠ¤ë¯¸ìŠ¤ì”¨, ë‹´ë°° í”¼ìš°ì‹œë‚˜ìš”?\n",
      "#Person2#: ë„¤.\n",
      "#Person1#: ë‹¹ì‹ ë„ ì•Œë‹¤ì‹œí”¼, ë‹´ë°°ëŠ” íì•”ê³¼ ì‹¬ì¥ë³‘ì˜ ì£¼ìš” ì›ì¸ì…ë‹ˆë‹¤. ì •ë§ë¡œ ëŠìœ¼ì…”ì•¼ í•©ë‹ˆë‹¤. \n",
      "#Person2#: ìˆ˜ë°± ë²ˆ ì‹œë„í–ˆì§€ë§Œ, ìŠµê´€ì„ ë²„ë¦¬ëŠ” ê²ƒì´ ì–´ë µìŠµë‹ˆë‹¤.\n",
      "#Person1#: ìš°ë¦¬ëŠ” ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ìˆ˜ì—…ê³¼ ì•½ë¬¼ë“¤ì„ ì œê³µí•˜ê³  ìˆìŠµë‹ˆë‹¤. ë‚˜ê°€ê¸° ì „ì— ë” ë§ì€ ì •ë³´ë¥¼ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "#Person2#: ì•Œê² ìŠµë‹ˆë‹¤, ê°ì‚¬í•©ë‹ˆë‹¤, ì˜ì‚¬ì„ ìƒë‹˜.\n",
      "train_label:\n",
      " ìŠ¤ë¯¸ìŠ¤ì”¨ê°€ ê±´ê°•ê²€ì§„ì„ ë°›ê³  ìˆê³ , í˜¸í‚¨ìŠ¤ ì˜ì‚¬ëŠ” ë§¤ë…„ ê±´ê°•ê²€ì§„ì„ ë°›ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤. í˜¸í‚¨ìŠ¤ ì˜ì‚¬ëŠ” ìŠ¤ë¯¸ìŠ¤ì”¨ê°€ ë‹´ë°°ë¥¼ ëŠëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ìˆ˜ì—…ê³¼ ì•½ë¬¼ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•  ê²ƒì…ë‹ˆë‹¤.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "val_data:\n",
      " #Person1#: ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ í•˜ë£¨ ì–´ë– ì…¨ì–´ìš”? \n",
      "#Person2#: ìš”ì¦˜ ìˆ¨ì‰¬ê¸°ê°€ ì¢€ í˜ë“¤ì–´ìš”.\n",
      "#Person1#: ìµœê·¼ì— ê°ê¸° ê°™ì€ ê²ƒì— ê±¸ë¦¬ì‹  ì ì´ ìˆë‚˜ìš”?\n",
      "#Person2#: ì•„ë‹ˆìš”, ê°ê¸°ëŠ” ì•„ë‹ˆì—ìš”. ê·¸ëƒ¥ ìˆ¨ì„ ì‰´ ë•Œë§ˆë‹¤ ê°€ìŠ´ì´ ë¬´ê²ê²Œ ëŠê»´ì ¸ìš”.\n",
      "#Person1#: ì•Œê³  ìˆëŠ” ì•Œë ˆë¥´ê¸°ê°€ ìˆë‚˜ìš”?\n",
      "#Person2#: ì•„ë‹ˆìš”, ì•Œê³  ìˆëŠ” ì•Œë ˆë¥´ê¸°ëŠ” ì—†ì–´ìš”.\n",
      "#Person1#: ì´ëŸ° ì¦ìƒì´ í•­ìƒ ë‚˜íƒ€ë‚˜ë‚˜ìš”, ì•„ë‹ˆë©´ í™œë™í•  ë•Œ ì£¼ë¡œ ë‚˜íƒ€ë‚˜ë‚˜ìš”?\n",
      "#Person2#: ìš´ë™ì„ í•  ë•Œ ë§ì´ ë‚˜íƒ€ë‚˜ìš”.\n",
      "#Person1#: ì €ëŠ” ë‹¹ì‹ ì„ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚´ì„œ ì²œì‹ì— ëŒ€í•œ ê²€ì‚¬ë¥¼ ë°›ê²Œ í•  ê±°ì˜ˆìš”.\n",
      "#Person2#: ë„ì™€ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤, ì˜ì‚¬ ì„ ìƒë‹˜.\n",
      "val_label:\n",
      " #Person2#ëŠ” ìˆ¨ì‰¬ê¸°ì— ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤. ì˜ì‚¬ëŠ” #Person1#ì—ê²Œ ì´ì— ëŒ€í•´ ë¬»ê³ , #Person2#ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚¼ ì˜ˆì •ì´ë‹¤. \n",
      "---------- Load data complete ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Make dataset complete ----------\n",
      "\n",
      "Encoder Input í† í° ê¸¸ì´ ë¶„ì„:\n",
      "í‰ê·  ê¸¸ì´: 512.00\n",
      "ìµœëŒ€ ê¸¸ì´: 512\n",
      "ìµœì†Œ ê¸¸ì´: 512\n",
      "\n",
      "Decoder Input í† í° ê¸¸ì´ ë¶„ì„:\n",
      "í‰ê·  ê¸¸ì´: 100.00\n",
      "ìµœëŒ€ ê¸¸ì´: 100\n",
      "ìµœì†Œ ê¸¸ì´: 100\n",
      "\n",
      "Decoder Output í† í° ê¸¸ì´ ë¶„ì„:\n",
      "í‰ê·  ê¸¸ì´: 100.00\n",
      "ìµœëŒ€ ê¸¸ì´: 100\n",
      "ìµœì†Œ ê¸¸ì´: 100\n",
      "---------- Make training arguments ----------\n",
      "---------- Make training arguments complete ----------\n",
      "---------- Make trainer ----------\n",
      "---------- Make trainer complete ----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/NLP/wandb/run-20241128_030449-8id4enir</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pearlzero21-sk-telecom/huggingface/runs/8id4enir' target=\"_blank\">peachy-pine-9</a></strong> to <a href='https://wandb.ai/pearlzero21-sk-telecom/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pearlzero21-sk-telecom/huggingface' target=\"_blank\">https://wandb.ai/pearlzero21-sk-telecom/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pearlzero21-sk-telecom/huggingface/runs/8id4enir' target=\"_blank\">https://wandb.ai/pearlzero21-sk-telecom/huggingface/runs/8id4enir</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2750' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2750/5000 20:10 < 16:30, 2.27 it/s, Epoch 11/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.602000</td>\n",
       "      <td>2.471662</td>\n",
       "      <td>0.222376</td>\n",
       "      <td>0.045046</td>\n",
       "      <td>0.210767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.239800</td>\n",
       "      <td>0.630388</td>\n",
       "      <td>0.359172</td>\n",
       "      <td>0.120610</td>\n",
       "      <td>0.343303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.590300</td>\n",
       "      <td>0.581226</td>\n",
       "      <td>0.367142</td>\n",
       "      <td>0.126740</td>\n",
       "      <td>0.352144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.534300</td>\n",
       "      <td>0.569818</td>\n",
       "      <td>0.372047</td>\n",
       "      <td>0.131487</td>\n",
       "      <td>0.356216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.502400</td>\n",
       "      <td>0.564034</td>\n",
       "      <td>0.373753</td>\n",
       "      <td>0.133171</td>\n",
       "      <td>0.359196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.479000</td>\n",
       "      <td>0.561199</td>\n",
       "      <td>0.374897</td>\n",
       "      <td>0.133941</td>\n",
       "      <td>0.358738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.458700</td>\n",
       "      <td>0.561418</td>\n",
       "      <td>0.372756</td>\n",
       "      <td>0.132909</td>\n",
       "      <td>0.357138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.440300</td>\n",
       "      <td>0.560033</td>\n",
       "      <td>0.382588</td>\n",
       "      <td>0.143190</td>\n",
       "      <td>0.367707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.424700</td>\n",
       "      <td>0.562510</td>\n",
       "      <td>0.380498</td>\n",
       "      <td>0.141244</td>\n",
       "      <td>0.364081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.411200</td>\n",
       "      <td>0.565318</td>\n",
       "      <td>0.374756</td>\n",
       "      <td>0.138198</td>\n",
       "      <td>0.360772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.399800</td>\n",
       "      <td>0.564333</td>\n",
       "      <td>0.379892</td>\n",
       "      <td>0.141642</td>\n",
       "      <td>0.365882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   #Person1##Person2# ì€ #Person1# ì—ê²Œ  ê°ê¸° ê°™ì€ ê°ê¸°ì— ê±¸ë¦¬ì‹  ì ì´ ìˆëŠ”ì§€ ë¬¼ì–´ë´…ë‹ˆë‹¤.                                                                             \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸°ì— ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤. ì˜ì‚¬ëŠ” #Person1# ì—ê²Œ ì´ì— ëŒ€í•´ ë¬»ê³ , #Person2# ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚¼ ì˜ˆì •ì´ë‹¤.                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ”#Person2##Person2# ëŠ” ì£¼ê°„ ìŠ¤ì¼€ì¤„ì„ ë”°ë¥´ê³  ìˆìœ¼ë©°, ê¸ˆìš”ì¼ì— ë‹¤ë¦¬ë¥¼ í•  ìˆ˜ ìˆì–´ í—¬ìŠ¤ì¥ì—ì„œ ë§Œë‚˜ì.                                                                            \n",
      "GOLD: #Person1# ì€ ì§€ë¯¸ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•˜ê³  íŒ”ê³¼ ë°°ë¥¼ ìš´ë™í•˜ë„ë¡ ì„¤ë“í•œë‹¤.                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” #Person1# ëŠ” #Person1# ì˜  ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶°ì•¼ í•´ìš”.                                                                                \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶”ë ¤ëŠ” ê³„íšì„ ì„¸ìš°ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ë ˆì‹œí”¼ë¥¼ #Person1# ì™€ ê³µìœ í•œë‹¤.                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# ì€ ê°ê¸° ê°™ì€ ê²ƒì— ê±¸ë¦¬ì…¨ë‹¤ê³  ë§í•©ë‹ˆë‹¤. #Person2# ëŠ” #Person1# ì—ê²Œ ì•Œë ˆë¥´ê¸°ê°€ ìˆë‹¤ê³  ë§í•©ë‹ˆë‹¤.                                                                          \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸°ì— ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤. ì˜ì‚¬ëŠ” #Person1# ì—ê²Œ ì´ì— ëŒ€í•´ ë¬»ê³ , #Person2# ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚¼ ì˜ˆì •ì´ë‹¤.                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# ê³¼ #Person2# ëŠ” #Person1# ì—ê²Œ #Person2# ì˜ ì£¼ê°„ ìŠ¤ì¼€ì¤„ì„ ë°”ê¾¸ìê³  ì œì•ˆí•œë‹¤.                                                                                \n",
      "GOLD: #Person1# ì€ ì§€ë¯¸ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•˜ê³  íŒ”ê³¼ ë°°ë¥¼ ìš´ë™í•˜ë„ë¡ ì„¤ë“í•œë‹¤.                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” #Person1# ì—ê²Œ ë” ì´ìƒ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ì§€ ë§ë¼ê³  ë§í•œë‹¤. #Person1# ëŠ” ë‹­ê³ ê¸°ë¥¼ ì¢‹ì•„í•œë‹¤.                                                                         \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶”ë ¤ëŠ” ê³„íšì„ ì„¸ìš°ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ë ˆì‹œí”¼ë¥¼ #Person1# ì™€ ê³µìœ í•œë‹¤.                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ê°ê¸° ê°™ì€ ê²ƒì— ê±¸ë¦¬ê±°ë‚˜ ìš´ë™ì„ í•  ë•Œ ë§ì´ ë‚˜íƒ€ë‚˜ì„œ ì²œì‹ì— ëŒ€í•œ ê²€ì‚¬ë¥¼ ë°›ê²Œ ë  ê²ƒì…ë‹ˆë‹¤.                                                                             \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸°ì— ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤. ì˜ì‚¬ëŠ” #Person1# ì—ê²Œ ì´ì— ëŒ€í•´ ë¬»ê³ , #Person2# ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚¼ ì˜ˆì •ì´ë‹¤.                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   ì§€ë¯¸ëŠ” #Person1# ì—ê²Œ ì˜¤í›„ì— ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•œë‹¤. #Person1# ì€ ë™ì˜í•œë‹¤.                                                                                \n",
      "GOLD: #Person1# ì€ ì§€ë¯¸ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•˜ê³  íŒ”ê³¼ ë°°ë¥¼ ìš´ë™í•˜ë„ë¡ ì„¤ë“í•œë‹¤.                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# ì€ #Person2# ì—ê²Œ ë” ì´ìƒ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶°ì•¼ í•œë‹¤ê³  ë§í•œë‹¤. #Person2# ëŠ” ë‹­ê³ ê¸°ë¥¼ ì¢‹ì•„í•œë‹¤.                                                                        \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶”ë ¤ëŠ” ê³„íšì„ ì„¸ìš°ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ë ˆì‹œí”¼ë¥¼ #Person1# ì™€ ê³µìœ í•œë‹¤.                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ìŠµë‹ˆë‹¤. #Person1# ëŠ” #Person2# ì—ê²Œ ì²œì‹ì— ëŒ€í•œ ê²€ì‚¬ë¥¼ ë°›ê²Œ í•  ê²ƒì…ë‹ˆë‹¤.                                                                              \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸°ì— ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤. ì˜ì‚¬ëŠ” #Person1# ì—ê²Œ ì´ì— ëŒ€í•´ ë¬»ê³ , #Person2# ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚¼ ì˜ˆì •ì´ë‹¤.                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   ì§€ë¯¸ëŠ” #Person1# ì—ê²Œ ì˜¤í›„ì— ìš´ë™í•˜ìê³  ì œì•ˆí•œë‹¤. #Person1# ì€ ë™ì˜í•œë‹¤.                                                                                  \n",
      "GOLD: #Person1# ì€ ì§€ë¯¸ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•˜ê³  íŒ”ê³¼ ë°°ë¥¼ ìš´ë™í•˜ë„ë¡ ì„¤ë“í•œë‹¤.                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# ê³¼ #Person2# ëŠ” ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶°ì•¼ í•œë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤. #Person1# ì€ ë‹­ê³ ê¸°ë¥¼ ì¢‹ì•„í•©ë‹ˆë‹¤.                                                                           \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶”ë ¤ëŠ” ê³„íšì„ ì„¸ìš°ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ë ˆì‹œí”¼ë¥¼ #Person1# ì™€ ê³µìœ í•œë‹¤.                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ìˆ¨ì‰¬ê¸°ê°€ ì¢€ í˜ë“¤ê³  ì²œì‹ì— ëŒ€í•œ ê²€ì‚¬ë¥¼ ë°›ê²Œ ë  ê²ƒì…ë‹ˆë‹¤.                                                                                    \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸°ì— ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤. ì˜ì‚¬ëŠ” #Person1# ì—ê²Œ ì´ì— ëŒ€í•´ ë¬»ê³ , #Person2# ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚¼ ì˜ˆì •ì´ë‹¤.                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   ì§€ë¯¸ëŠ” #Person1# ì—ê²Œ ì˜¤í›„ì— ìš´ë™í•˜ìê³  ì œì•ˆí•˜ì§€ë§Œ, #Person1# ì€ ì£¼ê°„ ìŠ¤ì¼€ì¤„ì„ ë”°ë¥´ê³  ìˆê¸° ë•Œë¬¸ì— ì˜¤í›„ì— ìš´ë™í•˜ìê³  ì œì•ˆí•œë‹¤.                                                                       \n",
      "GOLD: #Person1# ì€ ì§€ë¯¸ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•˜ê³  íŒ”ê³¼ ë°°ë¥¼ ìš´ë™í•˜ë„ë¡ ì„¤ë“í•œë‹¤.                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# ì€ #Person2# ì—ê²Œ ë” ì´ìƒ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶°ì•¼ í•œë‹¤ê³  ë§í•œë‹¤. #Person2# ëŠ” ë‹­ê³ ê¸°ë¥¼ ì¢‹ì•„í•œë‹¤.                                                                        \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶”ë ¤ëŠ” ê³„íšì„ ì„¸ìš°ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ë ˆì‹œí”¼ë¥¼ #Person1# ì™€ ê³µìœ í•œë‹¤.                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ìˆ¨ì‰¬ê¸°ê°€ ì¢€ í˜ë“¤ê³  ê°ê¸°ëŠ” ì•„ë‹ˆë©°, #Person1# ëŠ” #Person2# ì—ê²Œ ì²œì‹ì— ëŒ€í•œ ê²€ì‚¬ë¥¼ ë°›ê²Œ í•  ê²ƒì…ë‹ˆë‹¤.                                                                         \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸°ì— ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤. ì˜ì‚¬ëŠ” #Person1# ì—ê²Œ ì´ì— ëŒ€í•´ ë¬»ê³ , #Person2# ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚¼ ì˜ˆì •ì´ë‹¤.                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   ì§€ë¯¸ëŠ” #Person1# ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•˜ì§€ë§Œ, #Person1# ì€ ì£¼ê°„ ìŠ¤ì¼€ì¤„ì„ ë”°ë¥´ê³  ìˆì–´ì„œ #Person2# ê°€ ë‘ ë‚ ì„ ë°”ê¾¸ëŠ” ê²ƒì„ ê±°ë¶€í•œë‹¤.                                                                     \n",
      "GOLD: #Person1# ì€ ì§€ë¯¸ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•˜ê³  íŒ”ê³¼ ë°°ë¥¼ ìš´ë™í•˜ë„ë¡ ì„¤ë“í•œë‹¤.                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# ì€ #Person2# ì—ê²Œ ë” ì´ìƒ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶°ì•¼ í•œë‹¤ê³  ë§í•œë‹¤. #Person2# ëŠ” ë‹­ê³ ê¸°ë¥¼ ì¢‹ì•„í•œë‹¤.                                                                        \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶”ë ¤ëŠ” ê³„íšì„ ì„¸ìš°ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ë ˆì‹œí”¼ë¥¼ #Person1# ì™€ ê³µìœ í•œë‹¤.                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ìˆ¨ì‰¬ê¸°ê°€ ì¢€ í˜ë“¤ë‹¤ê³  #Person1# ì—ê²Œ ë§í•©ë‹ˆë‹¤. #Person1# ì€ #Person2# ì—ê²Œ ì²œì‹ì— ëŒ€í•œ ê²€ì‚¬ë¥¼ ë°›ê²Œ í•  ê²ƒì…ë‹ˆë‹¤.                                                                       \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸°ì— ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤. ì˜ì‚¬ëŠ” #Person1# ì—ê²Œ ì´ì— ëŒ€í•´ ë¬»ê³ , #Person2# ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚¼ ì˜ˆì •ì´ë‹¤.                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   ì§€ë¯¸ëŠ” #Person1# ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•˜ì§€ë§Œ, #Person1# ì€ ì£¼ê°„ ìŠ¤ì¼€ì¤„ì„ ë”°ë¥´ê³  ìˆì–´ì„œ #Person2# ëŠ” ë‘ ë‚ ì„ ë°”ê¾¸ê¸°ë¡œ ê²°ì •í•œë‹¤.                                                                     \n",
      "GOLD: #Person1# ì€ ì§€ë¯¸ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•˜ê³  íŒ”ê³¼ ë°°ë¥¼ ìš´ë™í•˜ë„ë¡ ì„¤ë“í•œë‹¤.                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# ì€ #Person2# ì—ê²Œ ë” ì´ìƒ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶°ì•¼ í•œë‹¤ê³  ë§í•œë‹¤. #Person2# ëŠ” ë‹­ê³ ê¸°ë¥¼ ì¢‹ì•„í•œë‹¤.                                                                        \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶”ë ¤ëŠ” ê³„íšì„ ì„¸ìš°ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ë ˆì‹œí”¼ë¥¼ #Person1# ì™€ ê³µìœ í•œë‹¤.                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ìˆ¨ì‰¬ê¸°ê°€ ì¢€ í˜ë“¤ë‹¤ê³  #Person1# ì—ê²Œ ë§í•©ë‹ˆë‹¤. #Person1# ëŠ” #Person2# ì—ê²Œ ì²œì‹ì— ëŒ€í•œ ê²€ì‚¬ë¥¼ ë°›ê²Œ í•  ê²ƒì…ë‹ˆë‹¤.                                                                 \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸°ì— ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤. ì˜ì‚¬ëŠ” #Person1# ì—ê²Œ ì´ì— ëŒ€í•´ ë¬»ê³ , #Person2# ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚¼ ì˜ˆì •ì´ë‹¤.                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   ì§€ë¯¸ëŠ” #Person1# ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•˜ì§€ë§Œ, #Person1# ì€ ì£¼ê°„ ìŠ¤ì¼€ì¤„ì„ ë”°ë¥´ê³  ìˆì–´ì„œ #Person2# ëŠ” ë™ì˜í•˜ì§€ ì•ŠëŠ”ë‹¤.                                                                 \n",
      "GOLD: #Person1# ì€ ì§€ë¯¸ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•˜ê³  íŒ”ê³¼ ë°°ë¥¼ ìš´ë™í•˜ë„ë¡ ì„¤ë“í•œë‹¤.                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# ì€ #Person2# ì—ê²Œ ë” ì´ìƒ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶°ì•¼ í•œë‹¤ê³  ë§í•œë‹¤. #Person2# ëŠ” ë‹­ê³ ê¸°ë¥¼ ì¢‹ì•„í•œë‹¤.                                                                  \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶”ë ¤ëŠ” ê³„íšì„ ì„¸ìš°ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ë ˆì‹œí”¼ë¥¼ #Person1# ì™€ ê³µìœ í•œë‹¤.                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ìˆ¨ì‰¬ê¸°ê°€ ì¢€ í˜ë“¤ë‹¤ê³  #Person1# ì—ê²Œ ë§í•©ë‹ˆë‹¤. #Person1# ì€ #Person2# ì—ê²Œ ì²œì‹ì— ëŒ€í•œ ê²€ì‚¬ë¥¼ ë°›ê²Œ í•  ê²ƒì…ë‹ˆë‹¤.                                                                       \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸°ì— ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤. ì˜ì‚¬ëŠ” #Person1# ì—ê²Œ ì´ì— ëŒ€í•´ ë¬»ê³ , #Person2# ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚¼ ì˜ˆì •ì´ë‹¤.                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   ì§€ë¯¸ëŠ” #Person1# ì—ê²Œ ê¸ˆìš”ì¼ì— ìš´ë™í•˜ìê³  ì œì•ˆí•˜ì§€ë§Œ, #Person1# ì€ ì£¼ê°„ ìŠ¤ì¼€ì¤„ì„ ë”°ë¥´ê³  ìˆë‹¤.                                                                              \n",
      "GOLD: #Person1# ì€ ì§€ë¯¸ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•˜ê³  íŒ”ê³¼ ë°°ë¥¼ ìš´ë™í•˜ë„ë¡ ì„¤ë“í•œë‹¤.                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# ì€ #Person2# ì—ê²Œ ë” ì´ìƒ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶°ì•¼ í•œë‹¤ê³  ë§í•œë‹¤. #Person2# ëŠ” ë‹­ê³ ê¸°ë¥¼ ì¢‹ì•„í•œë‹¤.                                                                        \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶”ë ¤ëŠ” ê³„íšì„ ì„¸ìš°ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ë ˆì‹œí”¼ë¥¼ #Person1# ì™€ ê³µìœ í•œë‹¤.                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ìˆ¨ì‰¬ê¸°ê°€ ì¢€ í˜ë“¤ë‹¤ê³  #Person1# ì—ê²Œ ë§í•©ë‹ˆë‹¤. #Person1# ëŠ” #Person2# ì—ê²Œ ì²œì‹ì— ëŒ€í•œ ê²€ì‚¬ë¥¼ ë°›ê²Œ í•  ê²ƒì…ë‹ˆë‹¤.                                                           \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸°ì— ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤. ì˜ì‚¬ëŠ” #Person1# ì—ê²Œ ì´ì— ëŒ€í•´ ë¬»ê³ , #Person2# ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚¼ ì˜ˆì •ì´ë‹¤.                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   ì§€ë¯¸ëŠ” #Person1# ì—ê²Œ ê¸ˆìš”ì¼ì— ìš´ë™í•˜ìê³  ì œì•ˆí•˜ì§€ë§Œ, #Person1# ì€ ì£¼ê°„ ìŠ¤ì¼€ì¤„ì„ ë”°ë¥´ê³  ìˆë‹¤.                                                                  \n",
      "GOLD: #Person1# ì€ ì§€ë¯¸ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•˜ê³  íŒ”ê³¼ ë°°ë¥¼ ìš´ë™í•˜ë„ë¡ ì„¤ë“í•œë‹¤.                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# ì€ #Person2# ì—ê²Œ ë” ì´ìƒ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶°ì•¼ í•œë‹¤ê³  ë§í•œë‹¤. #Person2# ëŠ” ë‹­ê³ ê¸°ë¥¼ ì¢‹ì•„í•œë‹¤.                                                            \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶”ë ¤ëŠ” ê³„íšì„ ì„¸ìš°ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ë ˆì‹œí”¼ë¥¼ #Person1# ì™€ ê³µìœ í•œë‹¤.                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ìˆ¨ì‰¬ê¸°ê°€ ì¢€ í˜ë“¤ë‹¤ê³  #Person1# ì—ê²Œ ë§í•©ë‹ˆë‹¤. #Person1# ëŠ” #Person2# ì—ê²Œ ì²œì‹ì— ëŒ€í•œ ê²€ì‚¬ë¥¼ ë°›ê²Œ í•  ê²ƒì…ë‹ˆë‹¤.                                                                  \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸°ì— ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤. ì˜ì‚¬ëŠ” #Person1# ì—ê²Œ ì´ì— ëŒ€í•´ ë¬»ê³ , #Person2# ë¥¼ í ì „ë¬¸ì˜ì—ê²Œ ë³´ë‚¼ ì˜ˆì •ì´ë‹¤.                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   ì§€ë¯¸ëŠ” #Person1# ì—ê²Œ ìš´ë™ ì‹œê°„ì„ ë³€ê²½í•´ ë‹¬ë¼ê³  ìš”ì²­í•˜ì§€ë§Œ, #Person1# ì€ ì£¼ê°„ ìŠ¤ì¼€ì¤„ì„ ë”°ë¥´ê³  ìˆê¸° ë•Œë¬¸ì— ë™ì˜í•˜ì§€ ì•ŠëŠ”ë‹¤.                                                                   \n",
      "GOLD: #Person1# ì€ ì§€ë¯¸ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•˜ê³  íŒ”ê³¼ ë°°ë¥¼ ìš´ë™í•˜ë„ë¡ ì„¤ë“í•œë‹¤.                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# ì€ #Person2# ì—ê²Œ ë” ì´ìƒ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶°ì•¼ í•œë‹¤ê³  ë§í•œë‹¤. #Person2# ëŠ” ë‹­ê³ ê¸°ë¥¼ ì¢‹ì•„í•˜ë©°, #Person1# ì€ ë‹­ê³ ê¸°ë¥¼ ì¢‹ì•„í•œë‹¤.                                                           \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— í•´ë¡œìš´ ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì„ ë©ˆì¶”ë ¤ëŠ” ê³„íšì„ ì„¸ìš°ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ë ˆì‹œí”¼ë¥¼ #Person1# ì™€ ê³µìœ í•œë‹¤.                                                                \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(loaded_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# CUDA ë©”ëª¨ë¦¬ ê´€ë¦¬ ì„¤ì •\n",
    "torch.cuda.empty_cache()  # ìºì‹œ ë¹„ìš°ê¸°\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)  # ë©”ëª¨ë¦¬ ì‚¬ìš© ìƒí™© í™•ì¸\n",
    "\n",
    "# ìµœëŒ€ ë¶„í•  í¬ê¸° ì„¤ì •\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ëª¨ë¸ ì¶”ë¡ í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°€ì¥ ìµœì‹  ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œë¥¼ configì— ë°˜ì˜\n",
    "loaded_config['inference']['ckt_path'] = \"/root/NLP/ckp/digit82/kobart-summarization/checkpoint-2750\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFGul3-rSscf"
   },
   "source": [
    "- test dataë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "id": "lV1Do7nlTylG"
   },
   "outputs": [],
   "source": [
    "# tokenization ê³¼ì •ê¹Œì§€ ì§„í–‰ëœ ìµœì¢…ì ìœ¼ë¡œ ëª¨ë¸ì— ì…ë ¥ë  ë°ì´í„°ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "def prepare_test_dataset(config,preprocessor, tokenizer):\n",
    "\n",
    "    test_file_path = os.path.join(config['general']['data_path'],'test.csv')\n",
    "\n",
    "    test_data = preprocessor.make_set_as_df(test_file_path,is_train=False)\n",
    "    test_id = test_data['fname']\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f'test_data:\\n{test_data[\"dialogue\"][0]}')\n",
    "    print('-'*150)\n",
    "\n",
    "    encoder_input_test , decoder_input_test = preprocessor.make_input(test_data,is_test=True)\n",
    "    print('-'*10, 'Load data complete', '-'*10,)\n",
    "\n",
    "    test_tokenized_encoder_inputs = tokenizer(encoder_input_test, return_tensors=\"pt\", padding=True,\n",
    "                    add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False,)\n",
    "    test_tokenized_decoder_inputs = tokenizer(decoder_input_test, return_tensors=\"pt\", padding=True,\n",
    "                    add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False,)\n",
    "\n",
    "    test_encoder_inputs_dataset = DatasetForInference(test_tokenized_encoder_inputs, test_id, len(encoder_input_test))\n",
    "    print('-'*10, 'Make dataset complete', '-'*10,)\n",
    "\n",
    "    return test_data, test_encoder_inputs_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "id": "eb49bLULT3aS"
   },
   "outputs": [],
   "source": [
    "# ì¶”ë¡ ì„ ìœ„í•œ tokenizerì™€ í•™ìŠµì‹œí‚¨ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "def load_tokenizer_and_model_for_test(config,device):\n",
    "    print('-'*10, 'Load tokenizer & model', '-'*10,)\n",
    "\n",
    "    model_name = config['general']['model_name']\n",
    "    ckt_path = config['inference']['ckt_path']\n",
    "    print('-'*10, f'Model Name : {model_name}', '-'*10,)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    special_tokens_dict = {'additional_special_tokens': config['tokenizer']['special_tokens']}\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "    generate_model = BartForConditionalGeneration.from_pretrained(ckt_path)\n",
    "    generate_model.resize_token_embeddings(len(tokenizer))\n",
    "    generate_model.to(device)\n",
    "    print('-'*10, 'Load tokenizer & model complete', '-'*10,)\n",
    "\n",
    "    return generate_model , tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "id": "Axzu9rsoGLgJ"
   },
   "outputs": [],
   "source": [
    "# í•™ìŠµëœ ëª¨ë¸ì´ ìƒì„±í•œ ìš”ì•½ë¬¸ì˜ ì¶œë ¥ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
    "def inference(config):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
    "    print('-'*10, f'device : {device}', '-'*10,)\n",
    "    print(torch.__version__)\n",
    "\n",
    "    generate_model , tokenizer = load_tokenizer_and_model_for_test(config,device)\n",
    "\n",
    "    data_path = config['general']['data_path']\n",
    "    preprocessor = Preprocess(config['tokenizer']['bos_token'], config['tokenizer']['eos_token'])\n",
    "\n",
    "    test_data, test_encoder_inputs_dataset = prepare_test_dataset(config,preprocessor, tokenizer)\n",
    "    dataloader = DataLoader(test_encoder_inputs_dataset, batch_size=config['inference']['batch_size'])\n",
    "\n",
    "    summary = []\n",
    "    text_ids = []\n",
    "    with torch.no_grad():\n",
    "        for item in tqdm(dataloader):\n",
    "            text_ids.extend(item['ID'])\n",
    "            generated_ids = generate_model.generate(input_ids=item['input_ids'].to('cuda:0'),\n",
    "                            no_repeat_ngram_size=config['inference']['no_repeat_ngram_size'],\n",
    "                            early_stopping=config['inference']['early_stopping'],\n",
    "                            max_length=config['inference']['generate_max_length'],\n",
    "                            num_beams=config['inference']['num_beams'],\n",
    "                        )\n",
    "            for ids in generated_ids:\n",
    "                result = tokenizer.decode(ids)\n",
    "                summary.append(result)\n",
    "\n",
    "    # ì •í™•í•œ í‰ê°€ë¥¼ ìœ„í•˜ì—¬ ë…¸ì´ì¦ˆì— í•´ë‹¹ë˜ëŠ” ìŠ¤í˜ì…œ í† í°ì„ ì œê±°í•©ë‹ˆë‹¤.\n",
    "    remove_tokens = config['inference']['remove_tokens']\n",
    "    preprocessed_summary = summary.copy()\n",
    "    for token in remove_tokens:\n",
    "        preprocessed_summary = [sentence.replace(token,\" \") for sentence in preprocessed_summary]\n",
    "\n",
    "    output = pd.DataFrame(\n",
    "        {\n",
    "            \"fname\": test_data['fname'],\n",
    "            \"summary\" : preprocessed_summary,\n",
    "        }\n",
    "    )\n",
    "    result_path = config['inference']['result_path']\n",
    "    if not os.path.exists(result_path):\n",
    "        os.makedirs(result_path)\n",
    "    output.to_csv(os.path.join(result_path, \"sum2_aug_bt_output.csv\"), index=False)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "id": "-pJ1ZXf-5V50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- device : cuda:0 ----------\n",
      "2.1.0\n",
      "---------- Load tokenizer & model ----------\n",
      "---------- Model Name : digit82/kobart-summarization ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Load tokenizer & model complete ----------\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "test_data:\n",
      "#Person1#: ë”ìŠ¨ ì”¨, ë°›ì•„ì“°ê¸° ì¢€ í•´ì£¼ì„¸ìš”. \n",
      "#Person2#: ë„¤, ì‹¤ì¥ë‹˜...\n",
      "#Person1#: ì´ê²ƒì€ ì˜¤ëŠ˜ ì˜¤í›„ê¹Œì§€ ëª¨ë“  ì§ì›ì—ê²Œ ë‚´ë¶€ ë©”ëª¨ë¡œ ì „ë‹¬ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ì¤€ë¹„ë˜ì…¨ë‚˜ìš”?\n",
      "#Person2#: ë„¤, ì‹¤ì¥ë‹˜. ì‹œì‘í•˜ì…”ë„ ë©ë‹ˆë‹¤.\n",
      "#Person1#: ëª¨ë“  ì§ì›ë“¤ì—ê²Œ ì£¼ì˜í•˜ë¼... ì¦‰ì‹œ íš¨ë ¥ì„ ë°œíœ˜í•˜ì—¬, ëª¨ë“  ì‚¬ë¬´ì‹¤ í†µì‹ ì€ ì´ë©”ì¼ í†µì‹ ê³¼ ê³µì‹ ë©”ëª¨ë¡œ ì œí•œë©ë‹ˆë‹¤. ê·¼ë¬´ ì‹œê°„ ë™ì•ˆ ì§ì›ë“¤ì´ ì¦‰ì‹œ ë©”ì‹œì§€ í”„ë¡œê·¸ë¨ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ ì—„ê²©íˆ ê¸ˆì§€ë©ë‹ˆë‹¤.\n",
      "#Person2#: ì‹¤ì¥ë‹˜, ì´ê²ƒì€ ë‚´ë¶€ í†µì‹ ì—ë§Œ ì ìš©ë˜ëŠ” ê±´ê°€ìš”? ì•„ë‹ˆë©´ ì™¸ë¶€ í†µì‹ ì—ë„ ì œí•œì´ ë˜ëŠ” ê±´ê°€ìš”?\n",
      "#Person1#: ì´ê²ƒì€ ëª¨ë“  í†µì‹ ì— ì ìš©ë˜ì–´ì•¼ í•©ë‹ˆë‹¤, ì´ ì‚¬ë¬´ì‹¤ ë‚´ì˜ ì§ì›ë“¤ ì‚¬ì´ë¿ë§Œ ì•„ë‹ˆë¼ ì™¸ë¶€ í†µì‹ ì—ë„ ë§ˆì°¬ê°€ì§€ì…ë‹ˆë‹¤.\n",
      "#Person2#: í•˜ì§€ë§Œ ì‹¤ì¥ë‹˜, ë§ì€ ì§ì›ë“¤ì´ ê³ ê°ê³¼ ì†Œí†µí•˜ê¸° ìœ„í•´ ì¦‰ì‹œ ë©”ì‹œì§€ë¥¼ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "#Person1#: ê·¸ë“¤ì€ ê·¸ë“¤ì˜ ì˜ì‚¬ì†Œí†µ ë°©ë²•ì„ ë°”ê¾¸ì–´ì•¼ë§Œ í•©ë‹ˆë‹¤. ì´ ì‚¬ë¬´ì‹¤ì—ì„œ ëˆ„êµ¬ë„ ì¦‰ì‹œ ë©”ì‹œì§€ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê¸°ë¥¼ ì›í•©ë‹ˆë‹¤. ë„ˆë¬´ ë§ì€ ì‹œê°„ì„ ë‚­ë¹„í•˜ê²Œ ë©ë‹ˆë‹¤! ì´ì œ, ë©”ëª¨ë¥¼ ê³„ì†í•´ì£¼ì„¸ìš”. ìš°ë¦¬ê°€ ì–´ë””ê¹Œì§€ í–ˆë‚˜ìš”?\n",
      "#Person2#: ì´ê²ƒì€ ë‚´ë¶€ì™€ ì™¸ë¶€ í†µì‹ ì— ì ìš©ë©ë‹ˆë‹¤.\n",
      "#Person1#: ê·¸ë ‡ìŠµë‹ˆë‹¤. ì¦‰ì‹œ ë©”ì‹œì§€ë¥¼ ê³„ì† ì‚¬ìš©í•˜ëŠ” ì–´ë–¤ ì§ì›ì´ë¼ë„ ë¨¼ì € ê²½ê³ ë¥¼ ë°›ê³  ì§ë¬´ ì •ì§€ì— ì²˜í•´ì§ˆ ê²ƒì…ë‹ˆë‹¤. ë‘ ë²ˆì§¸ ìœ„ë°˜ ì‹œì—ëŠ” ì§ì›ì€ í•´ê³ ì— ì²˜í•´ì§ˆ ê²ƒì…ë‹ˆë‹¤. ì´ ìƒˆë¡œìš´ ì •ì±…ì— ëŒ€í•œ ì–´ë–¤ ì§ˆë¬¸ì´ë¼ë„ ë¶€ì„œì¥ì—ê²Œ ì§ì ‘ ë¬¸ì˜í•˜ë©´ ë©ë‹ˆë‹¤.\n",
      "#Person2#: ê·¸ê²Œ ë‹¤ì‹ ê°€ìš”?\n",
      "#Person1#: ë„¤. ì´ ë©”ëª¨ë¥¼ ì˜¤í›„ 4ì‹œ ì „ì— ëª¨ë“  ì§ì›ì—ê²Œ íƒ€ì´í•‘í•˜ì—¬ ë°°í¬í•´ ì£¼ì„¸ìš”.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "---------- Load data complete ----------\n",
      "---------- Make dataset complete ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:38<00:00,  2.41s/it]\n"
     ]
    }
   ],
   "source": [
    "# í•™ìŠµëœ ëª¨ë¸ì˜ testë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "if __name__ == \"__main__\":\n",
    "    output = inference(loaded_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "id": "OsPmLfhbzZqS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>ë”ìŠ¨ ì”¨ëŠ” #Person1# ì—ê²Œ ëª¨ë“  ì‚¬ë¬´ì‹¤ í†µì‹ ì´ ì´ë©”ì¼ í†µì‹ ê³¼ ê³µì‹ ë©”ëª¨ë¡œ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>#Person2# ëŠ” #Person1# ì—ê²Œ êµí†µ ì²´ì¦ì— ê±¸ë ¸ë‹¤ê³  ë§í•œë‹¤. #Pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>ì¼€ì´íŠ¸ëŠ” ë§ˆìƒ¤ì™€ íˆì–´ë¡œê°€ 2ê°œì›” ë™ì•ˆ ë³„ê±° ì¤‘ì´ë‹¤ê°€ ì´í˜¼ì„ ì‹ ì²­í–ˆë‹¤ê³  #Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>ë¸Œë¼ì´ì–¸ì€ #Person1# ì˜ ìƒì¼ íŒŒí‹°ì—ì„œ #Person1# ê³¼ ì¶¤ì„ ì¶”ê³  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>#Person2# ëŠ” #Person1# ì—ê²Œ ì˜¬ë¦¼í”½ ìŠ¤íƒ€ë””ì›€ì— 5000ê°œì˜ ì¢Œì„ì´...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>test_495</td>\n",
       "      <td>ì°°ë¦¬ëŠ” ì•„ë¹ ë¥¼ ë°ë¦¬ëŸ¬ ê°€ì•¼í•˜ê¸° ë•Œë¬¸ì— ìƒˆ ê²Œì„ì— ëŒ€í•´ ì­ì—ê²Œ ì´ì•¼ê¸°í•œë‹¤. ì­ì€ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>test_496</td>\n",
       "      <td>#Person2# ëŠ” ì»¨íŠ¸ë¦¬ ìŒì•…ì— ê´€ì‹¬ì„ ê°€ì§€ê²Œ ëœ ê³„ê¸°ì™€ ë¼ë””ì˜¤ ë°©ì†¡êµ­ì—ì„œ ì¼...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>test_497</td>\n",
       "      <td>ì•¨ë¦¬ìŠ¤ëŠ” #Person1# ì—ê²Œ ê¸°ê³„ë¥¼ ì–´ë–»ê²Œ ì‚¬ìš©í•˜ëŠ”ì§€ ì•Œë ¤ì¤ë‹ˆë‹¤. #Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>test_498</td>\n",
       "      <td>ìŠ¤í‹°ë¸ŒëŠ” ê³„ì•½ì´ ë‹¤ìŒ ë‹¬ì— ëë‚˜ê¸° ë•Œë¬¸ì— ì§‘ì„ ì°¾ê³  ìˆë‹¤. ë§¤íŠœëŠ” ê·¸ë…€ì˜ ì´ì›ƒì¸...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>test_499</td>\n",
       "      <td>í”„ë­í¬ëŠ” ìŠ¹ì§„í•˜ê³  ì¹œêµ¬ë“¤ ëª¨ë‘ë¥¼ ìœ„í•œ í° íŒŒí‹°ë¥¼ ì—´ ì˜ˆì •ì´ë‹¤. ë²³ì‹œëŠ” íŒŒí‹°ì— ì°¸...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fname                                            summary\n",
       "0      test_0    ë”ìŠ¨ ì”¨ëŠ” #Person1# ì—ê²Œ ëª¨ë“  ì‚¬ë¬´ì‹¤ í†µì‹ ì´ ì´ë©”ì¼ í†µì‹ ê³¼ ê³µì‹ ë©”ëª¨ë¡œ...\n",
       "1      test_1   #Person2# ëŠ” #Person1# ì—ê²Œ êµí†µ ì²´ì¦ì— ê±¸ë ¸ë‹¤ê³  ë§í•œë‹¤. #Pe...\n",
       "2      test_2    ì¼€ì´íŠ¸ëŠ” ë§ˆìƒ¤ì™€ íˆì–´ë¡œê°€ 2ê°œì›” ë™ì•ˆ ë³„ê±° ì¤‘ì´ë‹¤ê°€ ì´í˜¼ì„ ì‹ ì²­í–ˆë‹¤ê³  #Pers...\n",
       "3      test_3    ë¸Œë¼ì´ì–¸ì€ #Person1# ì˜ ìƒì¼ íŒŒí‹°ì—ì„œ #Person1# ê³¼ ì¶¤ì„ ì¶”ê³  ...\n",
       "4      test_4   #Person2# ëŠ” #Person1# ì—ê²Œ ì˜¬ë¦¼í”½ ìŠ¤íƒ€ë””ì›€ì— 5000ê°œì˜ ì¢Œì„ì´...\n",
       "..        ...                                                ...\n",
       "494  test_495    ì°°ë¦¬ëŠ” ì•„ë¹ ë¥¼ ë°ë¦¬ëŸ¬ ê°€ì•¼í•˜ê¸° ë•Œë¬¸ì— ìƒˆ ê²Œì„ì— ëŒ€í•´ ì­ì—ê²Œ ì´ì•¼ê¸°í•œë‹¤. ì­ì€ ...\n",
       "495  test_496   #Person2# ëŠ” ì»¨íŠ¸ë¦¬ ìŒì•…ì— ê´€ì‹¬ì„ ê°€ì§€ê²Œ ëœ ê³„ê¸°ì™€ ë¼ë””ì˜¤ ë°©ì†¡êµ­ì—ì„œ ì¼...\n",
       "496  test_497    ì•¨ë¦¬ìŠ¤ëŠ” #Person1# ì—ê²Œ ê¸°ê³„ë¥¼ ì–´ë–»ê²Œ ì‚¬ìš©í•˜ëŠ”ì§€ ì•Œë ¤ì¤ë‹ˆë‹¤. #Pers...\n",
       "497  test_498    ìŠ¤í‹°ë¸ŒëŠ” ê³„ì•½ì´ ë‹¤ìŒ ë‹¬ì— ëë‚˜ê¸° ë•Œë¬¸ì— ì§‘ì„ ì°¾ê³  ìˆë‹¤. ë§¤íŠœëŠ” ê·¸ë…€ì˜ ì´ì›ƒì¸...\n",
       "498  test_499    í”„ë­í¬ëŠ” ìŠ¹ì§„í•˜ê³  ì¹œêµ¬ë“¤ ëª¨ë‘ë¥¼ ìœ„í•œ í° íŒŒí‹°ë¥¼ ì—´ ì˜ˆì •ì´ë‹¤. ë²³ì‹œëŠ” íŒŒí‹°ì— ì°¸...\n",
       "\n",
       "[499 rows x 2 columns]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output  # ê° ëŒ€í™”ë¬¸ì— ëŒ€í•œ ìš”ì•½ë¬¸ì´ ì¶œë ¥ë¨ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "083ea69907bb48d4a8fff919bac51aad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08d05bc20a96432badd459e1ffaf868e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "13651c09564a4337b8274c1cb436faa5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14f6c91d6c634379b498586c51e606e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21d2e54b5a0a4f79973a512105da43eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2307c6dcbe0141acb5e61baae19cade7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "285007b45236478ca147c6df752c8da4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a190bda0b72407e9a953cd2104dd3b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2fd3d7bbcd6948d8904d33001f95ea03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3645438ace1f4596a8dbc157b48c1521": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14f6c91d6c634379b498586c51e606e0",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_08d05bc20a96432badd459e1ffaf868e",
      "value": " 295/295 [00:00&lt;00:00, 21.3kB/s]"
     }
    },
    "3a04e871b74b45d7bf02fd33bb103577": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3bcd6b6b956347b29e1efa20a1d00542": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c284a826f6843f6aa47eacad478ac30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_affff1d8a89e4c14955d1b2aa39ff1ab",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_13651c09564a4337b8274c1cb436faa5",
      "value": "tokenizer.json: 100%"
     }
    },
    "45187decb58b4ad39ad532259c6277e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4747b668e2fa4ab58a449446f80030f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "52095cc7087243ac916055e569fd22f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c18f0e3bc35e44d9915c3f84cd282a26",
      "max": 109,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3a04e871b74b45d7bf02fd33bb103577",
      "value": 109
     }
    },
    "58001a60eacc44d5b38a68648adccde4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58c794fb7ce543a39fdf66d757f6eeab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f5fde5b0ac840a18bd5cc380e564ff6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_45187decb58b4ad39ad532259c6277e5",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "5dfcf310ca9e4e2794076098a5d69cea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3c284a826f6843f6aa47eacad478ac30",
       "IPY_MODEL_6caedd60c6b747469c82930be1f95d6d",
       "IPY_MODEL_64f2218f899d446393cfea44f206f0a6"
      ],
      "layout": "IPY_MODEL_d068f541df3f438dbd5138863e64b2f2"
     }
    },
    "64f2218f899d446393cfea44f206f0a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d22fbc2c5dbf422399e496c9b500025a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_775d8bbeceac4e2da4f21ab6235c89ed",
      "value": " 682k/682k [00:00&lt;00:00, 5.40MB/s]"
     }
    },
    "6caedd60c6b747469c82930be1f95d6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bcd6b6b956347b29e1efa20a1d00542",
      "max": 682133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2fd3d7bbcd6948d8904d33001f95ea03",
      "value": 682133
     }
    },
    "6f5fde5b0ac840a18bd5cc380e564ff6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "775d8bbeceac4e2da4f21ab6235c89ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8a6464a355f7464c989033965d418a8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2307c6dcbe0141acb5e61baae19cade7",
      "max": 295,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4747b668e2fa4ab58a449446f80030f5",
      "value": 295
     }
    },
    "a15af9e8158f4903b9189f3d322a5ef3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac00d6c2cf974b33a628acb3f1471316",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_285007b45236478ca147c6df752c8da4",
      "value": " 109/109 [00:00&lt;00:00, 9.44kB/s]"
     }
    },
    "ac00d6c2cf974b33a628acb3f1471316": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "affff1d8a89e4c14955d1b2aa39ff1ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c18f0e3bc35e44d9915c3f84cd282a26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d068f541df3f438dbd5138863e64b2f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d22fbc2c5dbf422399e496c9b500025a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de1a3f7701c243839fe03b930a9b9e30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ebc22683058a4f229c5588e52fc93536",
       "IPY_MODEL_52095cc7087243ac916055e569fd22f3",
       "IPY_MODEL_a15af9e8158f4903b9189f3d322a5ef3"
      ],
      "layout": "IPY_MODEL_21d2e54b5a0a4f79973a512105da43eb"
     }
    },
    "e920dbc173c045d1a32143349f1dff8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_58c794fb7ce543a39fdf66d757f6eeab",
       "IPY_MODEL_8a6464a355f7464c989033965d418a8a",
       "IPY_MODEL_3645438ace1f4596a8dbc157b48c1521"
      ],
      "layout": "IPY_MODEL_58001a60eacc44d5b38a68648adccde4"
     }
    },
    "ebc22683058a4f229c5588e52fc93536": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_083ea69907bb48d4a8fff919bac51aad",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_2a190bda0b72407e9a953cd2104dd3b2",
      "value": "special_tokens_map.json: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
